{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0975143c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (1.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from pandas) (2022.4)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from pandas) (1.23.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (2.10.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorflow) (1.49.1)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorflow) (22.9.24)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorflow) (4.3.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorflow) (61.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorflow) (2.10.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorflow) (0.27.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorflow) (1.2.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorflow) (3.19.6)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorflow) (1.23.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorflow) (14.0.6)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2022.9.24)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from packaging->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: tensorflow-gpu in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (2.10.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorflow-gpu) (22.9.24)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorflow-gpu) (2.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorflow-gpu) (61.2.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorflow-gpu) (2.10.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorflow-gpu) (1.49.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorflow-gpu) (14.0.6)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorflow-gpu) (1.23.3)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorflow-gpu) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorflow-gpu) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorflow-gpu) (3.7.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorflow-gpu) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorflow-gpu) (0.27.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorflow-gpu) (4.3.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorflow-gpu) (1.1.2)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorflow-gpu) (2.10.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorflow-gpu) (1.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorflow-gpu) (1.6.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorflow-gpu) (2.0.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorflow-gpu) (1.14.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorflow-gpu) (1.16.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorflow-gpu) (21.3)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorflow-gpu) (3.19.6)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-gpu) (0.37.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (2.28.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (3.4.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (2.2.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (1.8.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (2.12.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (0.4.6)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow-gpu) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu) (2.1.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow-gpu) (3.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow-gpu) (2.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages (from packaging->tensorflow-gpu) (3.0.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install tensorflow\n",
    "!pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mdc20\\AppData\\Local\\Temp\\ipykernel_30752\\3692057591.py:9: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy\n",
    "import PIL\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "tf.compat.v1.keras.backend.set_session(tf.compat.v1.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af8ec586",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "datasetdir = 'C:\\\\Users\\\\mdc20\\\\Downloads\\\\img'\n",
    "os.chdir(datasetdir)\n",
    "def constructImageClassDataFrame(shape, min_class_occurence = 1, class_list = None):\n",
    "    # Args: \n",
    "    #   Shape: Image shape (2D)\n",
    "    #   min_class_occurence: number of times class must occur in labeled dir in order to add it to the final sclass list\n",
    "    \n",
    "    \n",
    "    sub_dirs = [d for d in os.listdir(os.getcwd()) if os.path.isdir(os.path.join(datasetdir, d))]\n",
    "    \n",
    "    if class_list is None:\n",
    "        classes = defaultdict(lambda: 0)\n",
    "\n",
    "        for sub_dir in sub_dirs:\n",
    "            labels = sub_dir.split('_')\n",
    "            for label in labels:\n",
    "                classes[label] += 1\n",
    "        top_k_classes = [cls for cls in classes if classes[cls] >= min_class_occurence]\n",
    "        label_classes = top_k_classes    \n",
    "    else:\n",
    "        classes = class_list\n",
    "        label_classes = classes\n",
    "\n",
    "    \n",
    "    # classes = list(classes)\n",
    "    # print(\"Done calculating list of classes\")\n",
    "\n",
    "    # TODO: remove\n",
    "    # top_k_classes = ['Graphic', 'Tee', 'Tank', 'Dress', 'Shorts', 'Print', 'Skirt', 'Blouse', 'Top', 'Leggings', 'Sweater', 'Abstract', 'Romper', 'Jumpsuit', 'Floral', 'Cardigan',  'Stripe', 'Boxy','Joggers', 'Striped',  'Tribal', 'Jacket', 'Jeans' ]\n",
    "    # top_k_classes = ['Top', 'Blouse']\n",
    "\n",
    "    arr = [[labeled_dir, file] for labeled_dir in sub_dirs for file in os.listdir(labeled_dir) ]\n",
    "    print(\"Done parsing through directories\")\n",
    "    df = pd.DataFrame(data=arr, columns=[\"folder\",\"filename\"])\n",
    "\n",
    "\n",
    "\n",
    "    df['filename'] = df['folder'] + '/' + df['filename']\n",
    "    df['labels'] = df['folder'].apply(lambda x : [y for y in x.split('_') if y in label_classes] if len([y for y in x.split('_') if y in label_classes]) > 0 else None)\n",
    "\n",
    "    print(np.shape(df))\n",
    "    # index_names = df [df['labels'] == []].index\n",
    "    # Drop Dataframe if none of its labels are present in the selected classes\n",
    "    df = df[df.labels.notnull()]\n",
    "\n",
    "    # series_list = list()\n",
    "    # print(\"Creating OHE for classes\")\n",
    "    # for idx, cls in enumerate(classes):\n",
    "    #     if idx %50 == 0: print(idx)\n",
    "    #     series = df['filename'].apply(lambda x: 1 if cls in x else 0)\n",
    "    #     series_list.append(series)\n",
    "    #     # df[str(cls)] = 1 if df['folder'].str.contains(str(cls)) else 0\n",
    "    \n",
    "    # df = pd.concat([df, series_list], axis=1)\n",
    "\n",
    "    #     files = os.listdir(labeled_dir)\n",
    "    #     labels = labeled_dir.split(\"_\")\n",
    "    #     for file in files:\n",
    "    #         continue\n",
    "            # df.loc[len(df.index)] = [os.path.join(datasetdir, labeled_dir), labels]\n",
    "\n",
    "    \n",
    "    # df.head()\n",
    "\n",
    "    return df, label_classes\n",
    "\n",
    "# df, top_k_classes = constructImageClassDataFrame(shape = (256,256), min_class_occurence=10,class_list=['Shirt','Shorts'])\n",
    "# print(df.head(100))\n",
    "# print(np.shape(df))\n",
    "# print(top_k_classes)\n",
    "# print(np.shape(top_k_classes))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9523a500",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetdir = 'C:\\\\Users\\\\mdc20\\\\Downloads\\\\img'\n",
    "os.chdir(datasetdir)\n",
    "\n",
    "from msilib.schema import Directory\n",
    "from random import shuffle\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "\n",
    "def DataLoad(shape, preprocessing): \n",
    "    '''Create the training and validation datasets for \n",
    "    a given image shape.\n",
    "    '''\n",
    "    imgdatagen = ImageDataGenerator(\n",
    "        preprocessing_function = preprocessing,\n",
    "        horizontal_flip = True, \n",
    "        validation_split = 0.1,\n",
    "        rescale = 1.0/255, \n",
    "    )\n",
    "\n",
    "    height, width = shape\n",
    "\n",
    "    df, classes = constructImageClassDataFrame(shape, class_list=['Shirt','Shorts','Dress','Skirt','Hoodie','Jumpsuit'])\n",
    "\n",
    "    print(df.sample(n=10))\n",
    "    # Modify dataframe to only take images with references to classes\n",
    "\n",
    "    classes = list(classes)\n",
    "    print(\"Num classes #\")\n",
    "    print(len(classes)) \n",
    "    # for subdir\n",
    "\n",
    "    train_dataset = imgdatagen.flow_from_dataframe(\n",
    "        dataframe = df,\n",
    "        directory = datasetdir,\n",
    "        x_col=\"filename\",\n",
    "        y_col=\"labels\",\n",
    "        batch_size = batch_size,\n",
    "        seed = 42,\n",
    "        shuffle = True,\n",
    "        class_mode=\"categorical\",\n",
    "        classes = classes,\n",
    "        subset = 'training'\n",
    "    )\n",
    "    val_dataset = imgdatagen.flow_from_dataframe(\n",
    "        dataframe = df,\n",
    "        directory = datasetdir,\n",
    "        x_col=\"filename\",\n",
    "        y_col=\"labels\",\n",
    "        batch_size = batch_size,\n",
    "        seed = 42,\n",
    "        shuffle = True,\n",
    "        class_mode=\"categorical\",\n",
    "        classes = classes,\n",
    "        subset = 'validation'\n",
    "    )\n",
    "\n",
    "    # train_dataset = imgdatagen.flow_from_directory(\n",
    "    #     os.getcwd(),\n",
    "    #     target_size = (height, width), \n",
    "    #     batch_size = batch_size,\n",
    "    #     classes = classes,\n",
    "    #     class_mode = 'categorical',\n",
    "    #     subset = 'training', \n",
    "    # )\n",
    "\n",
    "    # val_dataset = imgdatagen.flow_from_directory(\n",
    "    #     os.getcwd(),\n",
    "    #     target_size = (height, width), \n",
    "    #     batch_size = batch_size,\n",
    "    #     classes = classes,\n",
    "    #     class_mode = 'categorical',\n",
    "    #     subset = 'validation'\n",
    "    # )\n",
    "    return train_dataset, val_dataset, \n",
    "\n",
    "# train_dataset, val_dataset = DataLoad((350,350), preprocessing=preprocess_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2383f50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done parsing through directories\n",
      "(289219, 3)\n",
      "                                         folder  \\\n",
      "145646          High-Waisted_Denim_Pencil_Skirt   \n",
      "127664                  Floral_Scuba_Knit_Skirt   \n",
      "165916  Life_in_Progress_Pinstripe_Denim_Shorts   \n",
      "269133                    Tribal_Print_Jumpsuit   \n",
      "135061                    Geo_Halter_Maxi_Dress   \n",
      "179792         Metallic_Chevron-Patterned_Dress   \n",
      "121865           Floral_Lace_Elasticized_Shorts   \n",
      "19042                Beaded_Tuxedo_Stripe_Skirt   \n",
      "196160                 Paisley_Print_Maxi_Skirt   \n",
      "231558              Sleeveless_Zip-Front_Hoodie   \n",
      "\n",
      "                                                 filename      labels  \n",
      "145646   High-Waisted_Denim_Pencil_Skirt/img_00000029.jpg     [Skirt]  \n",
      "127664           Floral_Scuba_Knit_Skirt/img_00000013.jpg     [Skirt]  \n",
      "165916  Life_in_Progress_Pinstripe_Denim_Shorts/img_00...    [Shorts]  \n",
      "269133             Tribal_Print_Jumpsuit/img_00000032.jpg  [Jumpsuit]  \n",
      "135061             Geo_Halter_Maxi_Dress/img_00000033.jpg     [Dress]  \n",
      "179792  Metallic_Chevron-Patterned_Dress/img_00000024.jpg     [Dress]  \n",
      "121865    Floral_Lace_Elasticized_Shorts/img_00000011.jpg    [Shorts]  \n",
      "19042         Beaded_Tuxedo_Stripe_Skirt/img_00000010.jpg     [Skirt]  \n",
      "196160          Paisley_Print_Maxi_Skirt/img_00000047.jpg     [Skirt]  \n",
      "231558       Sleeveless_Zip-Front_Hoodie/img_00000008.jpg    [Hoodie]  \n",
      "Num classes #\n",
      "6\n",
      "Found 105385 validated image filenames belonging to 6 classes.\n",
      "Found 11709 validated image filenames belonging to 6 classes.\n",
      "<class 'keras.preprocessing.image.DataFrameIterator'>\n",
      "<class 'keras.preprocessing.image.DataFrameIterator'>\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 1. 0. 0. 0.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[ 1.  8. 41.  8.  4.  3.]\n",
      "(64, 256, 256, 3)\n",
      "(64, 6)\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "\n",
    "# Create custom preproocessing routine\n",
    "\n",
    "\n",
    "train_dataset, val_dataset = DataLoad((256,256), preprocessing=preprocess_input)\n",
    "\n",
    "print(type(train_dataset))\n",
    "print(type(val_dataset))\n",
    "# print(train_dataset.shape())\n",
    "\n",
    "X_train, y_train = next(train_dataset)\n",
    "\n",
    "print(type(X_train))\n",
    "print(y_train[0])\n",
    "print(np.sum(y_train, axis=1))\n",
    "print(np.sum(y_train, axis=0))\n",
    "print(np.shape(X_train))\n",
    "print(np.shape(y_train))\n",
    "# print(y_train.shape())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "76770cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_peek = y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be206065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, None, None, 3)]   0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, None, None, 64)    1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, None, None, 64)    36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, None, None, 128)   73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, None, None, 128)   147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, None, None, 128)   0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, None, None, 256)   295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, None, None, 256)   590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, None, None, 256)   590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, None, None, 256)   0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, None, None, 512)   1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16 = keras.applications.vgg16\n",
    "conv_model = vgg16.VGG16(weights='imagenet', include_top=False)\n",
    "conv_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5049c7b7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4d62db8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 256, 256, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 256, 256, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 128, 128, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 128, 128, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 128, 128, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 64, 64, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 64, 64, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 64, 64, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 64, 64, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 32, 32, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 16, 16, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 32768)             0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 100)               3276900   \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 6)                 606       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,012,394\n",
      "Trainable params: 3,297,706\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_model = vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(256,256,3))\n",
    "\n",
    "# flatten the output of the convolutional part: \n",
    "x = keras.layers.Flatten()(conv_model.output)\n",
    "# three hidden layers}\n",
    "x = keras.layers.Dense(100, activation='relu')(x)\n",
    "x = keras.layers.Dense(100, activation='relu')(x)\n",
    "x = keras.layers.Dense(100, activation='relu')(x)\n",
    "# final softmax layer with 40 categories\n",
    "\n",
    "predictions = keras.layers.Dense(6, activation = 'softmax')(x)\n",
    "for layer in conv_model.layers:\n",
    "    layer.trainable = False\n",
    "# creating the full model:\n",
    "full_model = keras.models.Model(inputs=conv_model.input, outputs=predictions)\n",
    "full_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508fbf07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cd2c730b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tf.keras.losses import BinaryCrossentropy\n",
    "\n",
    "cce = tf.keras.losses.CategoricalCrossentropy(reduction=tf.keras.losses.Reduction.SUM, from_logits=False)\n",
    "# bce = tf.keras.losses.binary_crossentropy\n",
    "\n",
    "# bce = BinaryCrossentropy()\n",
    "full_model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=keras.optimizers.Adamax(learning_rate=0.001),\n",
    "                  metrics=['acc', tf.keras.metrics.CategoricalCrossentropy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "85fcbe8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 14644894508509338167\n",
       " xla_global_id: -1,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 5762973696\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 5296306321352949287\n",
       " physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3060 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\"\n",
       " xla_global_id: 416903419]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configure run environment\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "device_lib.list_local_devices()\n",
    "# tf.config.list_physical_devices('CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "90b98a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1647/1647 [==============================] - 673s 405ms/step - loss: 0.8886 - acc: 0.7543 - categorical_crossentropy: 0.8886 - val_loss: 1.5232 - val_acc: 0.7742 - val_categorical_crossentropy: 1.5232\n",
      "Epoch 2/10\n",
      "1647/1647 [==============================] - 683s 414ms/step - loss: 5.9185 - acc: 0.6518 - categorical_crossentropy: 5.9185 - val_loss: 16.8796 - val_acc: 0.5027 - val_categorical_crossentropy: 16.8796\n",
      "Epoch 3/10\n",
      "1303/1647 [======================>.......] - ETA: 2:06 - loss: 21.5287 - acc: 0.5891 - categorical_crossentropy: 21.5287"
     ]
    }
   ],
   "source": [
    "from plot_keras_history import show_history, plot_history\n",
    "history = full_model.fit(\n",
    "    train_dataset, \n",
    "    validation_data = val_dataset,\n",
    "    workers=1,\n",
    "    epochs=10,\n",
    ")\n",
    "\n",
    "full_model.save('type_kernel.keras_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e44556e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10392/10392 [==============================] - 186s 18ms/step - loss: 0.5118 - acc: 0.7635 - categorical_crossentropy: 0.5118 - val_loss: 0.8866 - val_acc: 0.4163 - val_categorical_crossentropy: 0.8866\n",
      "Epoch 2/20\n",
      "10392/10392 [==============================] - 184s 18ms/step - loss: 0.4846 - acc: 0.7754 - categorical_crossentropy: 0.4846 - val_loss: 0.7567 - val_acc: 0.5193 - val_categorical_crossentropy: 0.7567\n",
      "Epoch 3/20\n",
      "10392/10392 [==============================] - 183s 18ms/step - loss: 0.4709 - acc: 0.7823 - categorical_crossentropy: 0.4709 - val_loss: 1.0742 - val_acc: 0.4362 - val_categorical_crossentropy: 1.0742\n",
      "Epoch 4/20\n",
      "10392/10392 [==============================] - 183s 18ms/step - loss: 0.4617 - acc: 0.7865 - categorical_crossentropy: 0.4617 - val_loss: 0.9494 - val_acc: 0.4645 - val_categorical_crossentropy: 0.9494\n",
      "Epoch 5/20\n",
      "10392/10392 [==============================] - 182s 18ms/step - loss: 0.4522 - acc: 0.7917 - categorical_crossentropy: 0.4522 - val_loss: 0.9985 - val_acc: 0.4815 - val_categorical_crossentropy: 0.9985\n",
      "Epoch 6/20\n",
      "10392/10392 [==============================] - 179s 17ms/step - loss: 0.4429 - acc: 0.7974 - categorical_crossentropy: 0.4429 - val_loss: 1.1955 - val_acc: 0.4030 - val_categorical_crossentropy: 1.1955\n",
      "Epoch 7/20\n",
      "10392/10392 [==============================] - 178s 17ms/step - loss: 0.4338 - acc: 0.8016 - categorical_crossentropy: 0.4338 - val_loss: 0.7631 - val_acc: 0.5782 - val_categorical_crossentropy: 0.7631\n",
      "Epoch 8/20\n",
      "10392/10392 [==============================] - 178s 17ms/step - loss: 0.4246 - acc: 0.8059 - categorical_crossentropy: 0.4246 - val_loss: 1.0760 - val_acc: 0.4755 - val_categorical_crossentropy: 1.0760\n",
      "Epoch 9/20\n",
      "10392/10392 [==============================] - 179s 17ms/step - loss: 0.4174 - acc: 0.8112 - categorical_crossentropy: 0.4174 - val_loss: 0.9696 - val_acc: 0.5165 - val_categorical_crossentropy: 0.9696\n",
      "Epoch 10/20\n",
      "10392/10392 [==============================] - 185s 18ms/step - loss: 0.4090 - acc: 0.8138 - categorical_crossentropy: 0.4090 - val_loss: 0.9302 - val_acc: 0.5286 - val_categorical_crossentropy: 0.9302\n",
      "Epoch 11/20\n",
      "10392/10392 [==============================] - 184s 18ms/step - loss: 0.3985 - acc: 0.8206 - categorical_crossentropy: 0.3985 - val_loss: 0.8476 - val_acc: 0.5765 - val_categorical_crossentropy: 0.8476\n",
      "Epoch 12/20\n",
      "10392/10392 [==============================] - 186s 18ms/step - loss: 0.3898 - acc: 0.8269 - categorical_crossentropy: 0.3898 - val_loss: 1.2277 - val_acc: 0.4564 - val_categorical_crossentropy: 1.2277\n",
      "Epoch 13/20\n",
      "10392/10392 [==============================] - 183s 18ms/step - loss: 0.3793 - acc: 0.8325 - categorical_crossentropy: 0.3793 - val_loss: 1.1566 - val_acc: 0.4760 - val_categorical_crossentropy: 1.1566\n",
      "Epoch 14/20\n",
      "10392/10392 [==============================] - 183s 18ms/step - loss: 0.3715 - acc: 0.8371 - categorical_crossentropy: 0.3715 - val_loss: 1.2107 - val_acc: 0.4962 - val_categorical_crossentropy: 1.2107\n",
      "Epoch 15/20\n",
      "10392/10392 [==============================] - 184s 18ms/step - loss: 0.3626 - acc: 0.8416 - categorical_crossentropy: 0.3626 - val_loss: 1.1733 - val_acc: 0.5162 - val_categorical_crossentropy: 1.1733\n",
      "Epoch 16/20\n",
      "10392/10392 [==============================] - 196s 19ms/step - loss: 0.3542 - acc: 0.8472 - categorical_crossentropy: 0.3542 - val_loss: 1.2097 - val_acc: 0.5089 - val_categorical_crossentropy: 1.2097\n",
      "Epoch 17/20\n",
      "10392/10392 [==============================] - 198s 19ms/step - loss: 0.3433 - acc: 0.8511 - categorical_crossentropy: 0.3433 - val_loss: 1.1965 - val_acc: 0.4847 - val_categorical_crossentropy: 1.1965\n",
      "Epoch 18/20\n",
      "10392/10392 [==============================] - 198s 19ms/step - loss: 0.3356 - acc: 0.8557 - categorical_crossentropy: 0.3356 - val_loss: 1.2359 - val_acc: 0.5020 - val_categorical_crossentropy: 1.2359\n",
      "Epoch 19/20\n",
      "10392/10392 [==============================] - 204s 20ms/step - loss: 0.3281 - acc: 0.8601 - categorical_crossentropy: 0.3281 - val_loss: 1.3215 - val_acc: 0.5127 - val_categorical_crossentropy: 1.3215\n",
      "Epoch 20/20\n",
      "10392/10392 [==============================] - 305s 29ms/step - loss: 0.3172 - acc: 0.8646 - categorical_crossentropy: 0.3172 - val_loss: 1.6415 - val_acc: 0.4426 - val_categorical_crossentropy: 1.6415\n"
     ]
    }
   ],
   "source": [
    "history3 = full_model.fit(\n",
    "    train_dataset, \n",
    "    validation_data = val_dataset,\n",
    "    workers=1,\n",
    "    epochs=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b172830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_model.save('sparse_categorical_cross_entropy.h5')\n",
    "full_model.save('39_acc.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d390f2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('cat_cross_entropy_16_classes.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b23d6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "x_val, y_val = next(val_dataset)\n",
    "y_prediction = model.predict(x_val)\n",
    "print(y_prediction[2])\n",
    "print(y_val[2])\n",
    "print(np.shape(y_prediction))\n",
    "# preds = np.argmax(y_prediction, axis=1)\n",
    "# print(preds)\n",
    "\n",
    "k = 4\n",
    "axis = 1 # Search for top k values in row\n",
    "top_k_indx = np.argpartition(y_prediction, -4, axis=axis)[-4:].T\n",
    "print(top_k_indx)\n",
    "print(np.shape(top_k_indx))\n",
    "# result = confusion_matrix(y_val, y_prediction, normalize='y_pred=')\n",
    "# print(y_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8302f478",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('gpu3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "b689eaeee660c5f4e77cc22f066091ae7dcd8b72ca1cd0b8aadc4281bbfd7404"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
