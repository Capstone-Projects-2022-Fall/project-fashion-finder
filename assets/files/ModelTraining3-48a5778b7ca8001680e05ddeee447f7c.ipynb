{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0975143c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "43\n",
      "43\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas | wc -l\n",
    "!pip install tensorflow | wc -l\n",
    "!pip install tensorflow-gpu | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c63170b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\\\\\wsl.localhost\\\\Ubuntu-20.04\\\\home\\\\mdc20\\\\repos\\\\personal\\\\project-fashion-finder\\\\model\\\\src'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1a01073",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_LIST_14 = [\"Tee\",\"Tank\",\"Dress\",\"Shorts\",\"Skirt\",\"Jumpsuit\",\"Sweater\",\"Blazer\",\"Striped\",\"Cardigan\",\"Blouse\",\"Romper\",\"Sweatpants\",\"Jacket\"]\n",
    "CLASS_LIST_29 = [\"Tee\",\"Tank\",\"Dress\",\"Shorts\",\"Skirt\",\"Jumpsuit\",\"Sweater\",\"Blazer\",\"Striped\",\"Cardigan\",\"Blouse\",\"Romper\",\"Sweatpants\",\"Jacket\", \"Jeans\", \"Poncho\", \"Button-Down\", \"Pencil\", \"Maxi\",  \"Floral\", \"Pleated\", \"Mesh\",\"Bandana\", \"Tie-Dye\", \"Culottes\", \"Embroidered\", \"Kimono\",\"Chevron\", \"Buttoned\"]\n",
    "CLASS_LIST_35 = [\"Tee\",\"Tank\",\"Dress\",\"Shirt\",\"Shorts\",\"Skirt\",\"Hoodie\",\"Jumpsuit\",\"Cargo\",\"Turtleneck\",\"Sweater\",\"Plaid\",\"Blazer\",\"Striped\",\"Cardigan\",\"Blouse\",\"Romper\",\"Jacket\",\"Jeans\",\"Maxi\",\"Floral\",\"Denim\",\"Trench\",\"Baroque\",\"Ornate\",\"Belted\",\"Jersey\",\"Sweatshorts\",\"PJ\",\"Parka\",\"Polka\",\"Beaded\",\"Shawl\",\"Bodycon\",\"Abstract\"]\n",
    "CLASS_LIST_21 = [\"Tee\",\"Tank\",\"Dress\",\"Shorts\",\"Skirt\",\"Hoodie\",\"Jumpsuit\",\"Sweater\",\"Blazer\",\"Striped\",\"Cardigan\",\"Blouse\",\"Jacket\",\"Jeans\",\"Maxi\",\"Floral\",\"Denim\",\"Sweatshorts\",\"Polka\",\"Shawl\",\"Bodycon\"]\n",
    "CLASS_LIST_2 = [\"Dress\", \"Jeans\"]\n",
    "CLASS_LIST = CLASS_LIST_21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy\n",
    "import PIL\n",
    "from PIL import Image\n",
    "PIL.Image.MAX_IMAGE_PIXELS = None\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "tf.compat.v1.keras.backend.set_session(tf.compat.v1.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af8ec586",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "datasetdir = 'C:\\\\Users\\\\mdc20\\\\Downloads\\\\img'\n",
    "os.chdir(datasetdir)\n",
    "def constructImageClassDataFrame(shape, min_class_occurence = 1, class_list = CLASS_LIST):\n",
    "    # Args: \n",
    "    #   Shape: Image shape (2D)\n",
    "    #   min_class_occurence: number of times class must occur in labeled dir in order to add it to the final sclass list\n",
    "    \n",
    "    \n",
    "    sub_dirs = [d for d in os.listdir(os.getcwd()) if os.path.isdir(os.path.join(datasetdir, d))]\n",
    "    \n",
    "    if class_list is None:\n",
    "        classes = defaultdict(lambda: 0)\n",
    "\n",
    "        for sub_dir in sub_dirs:\n",
    "            labels = sub_dir.split('_')\n",
    "            for label in labels:\n",
    "                classes[label] += 1\n",
    "        top_k_classes = [cls for cls in classes if classes[cls] >= min_class_occurence]\n",
    "        label_classes = top_k_classes    \n",
    "    else:\n",
    "        classes = class_list\n",
    "        label_classes = classes\n",
    "\n",
    "    \n",
    "    # classes = list(classes)\n",
    "    # print(\"Done calculating list of classes\")\n",
    "\n",
    "    # TODO: remove\n",
    "    # top_k_classes = ['Graphic', 'Tee', 'Tank', 'Dress', 'Shorts', 'Print', 'Skirt', 'Blouse', 'Top', 'Leggings', 'Sweater', 'Abstract', 'Romper', 'Jumpsuit', 'Floral', 'Cardigan',  'Stripe', 'Boxy','Joggers', 'Striped',  'Tribal', 'Jacket', 'Jeans' ]\n",
    "    # top_k_classes = ['Top', 'Blouse']\n",
    "\n",
    "    arr = [[labeled_dir, file] for labeled_dir in sub_dirs for file in os.listdir(labeled_dir) ]\n",
    "    print(\"Done parsing through directories\")\n",
    "    df = pd.DataFrame(data=arr, columns=[\"folder\",\"filename\"])\n",
    "\n",
    "\n",
    "\n",
    "    df['filename'] = df['folder'] + '/' + df['filename']\n",
    "    df['labels'] = df['folder'].apply(lambda x : [y for y in x.split('_') if y in label_classes] if len([y for y in x.split('_') if y in label_classes]) > 0 else None)\n",
    "\n",
    "    print(np.shape(df))\n",
    "    # index_names = df [df['labels'] == []].index\n",
    "    # Drop Dataframe if none of its labels are present in the selected classes\n",
    "    df = df[df.labels.notnull()]\n",
    "\n",
    "    # series_list = list()\n",
    "    # print(\"Creating OHE for classes\")\n",
    "    # for idx, cls in enumerate(classes):\n",
    "    #     if idx %50 == 0: print(idx)\n",
    "    #     series = df['filename'].apply(lambda x: 1 if cls in x else 0)\n",
    "    #     series_list.append(series)\n",
    "    #     # df[str(cls)] = 1 if df['folder'].str.contains(str(cls)) else 0\n",
    "    \n",
    "    # df = pd.concat([df, series_list], axis=1)\n",
    "\n",
    "    #     files = os.listdir(labeled_dir)\n",
    "    #     labels = labeled_dir.split(\"_\")\n",
    "    #     for file in files:\n",
    "    #         continue\n",
    "            # df.loc[len(df.index)] = [os.path.join(datasetdir, labeled_dir), labels]\n",
    "\n",
    "    \n",
    "    # df.head()\n",
    "\n",
    "    return df\n",
    "\n",
    "# df, top_k_classes = constructImageClassDataFrame(shape = (256,256), min_class_occurence=10,class_list=['Shirt','Shorts'])\n",
    "# print(df.head(100))\n",
    "# print(np.shape(df))\n",
    "# print(top_k_classes)\n",
    "# print(np.shape(top_k_classes))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9523a500",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetdir = 'E:\\\\img_highres'\n",
    "os.chdir(datasetdir)\n",
    "\n",
    "from msilib.schema import Directory\n",
    "from random import shuffle\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "BATCH_SIZE = 64\n",
    "IMG_SHAPE = (224,224)\n",
    "\n",
    "\n",
    "def DataLoad(shape, preprocessing): \n",
    "    '''Create the training and validation datasets for \n",
    "    a given image shape.\n",
    "    '''\n",
    "    imgdatagen = ImageDataGenerator(\n",
    "        preprocessing_function = preprocessing,\n",
    "        horizontal_flip = True, \n",
    "        validation_split = 0.1,\n",
    "        rescale = 1.0/255, \n",
    "    )\n",
    "\n",
    "    height, width = shape\n",
    "\n",
    "    df = constructImageClassDataFrame(shape, class_list=CLASS_LIST)\n",
    "\n",
    "    print(df.sample(n=10))\n",
    "    # Modify dataframe to only take images with references to classes\n",
    "\n",
    "    print(\"Num classes #\")\n",
    "    print(len(CLASS_LIST)) \n",
    "    # for subdir\n",
    "\n",
    "    train_dataset = imgdatagen.flow_from_dataframe(\n",
    "        dataframe = df,\n",
    "        directory = datasetdir,\n",
    "        x_col=\"filename\",\n",
    "        y_col=\"labels\",\n",
    "        target_size = IMG_SHAPE,\n",
    "        seed = 42,\n",
    "        shuffle = True,\n",
    "        batch_size = BATCH_SIZE,\n",
    "        class_mode=\"categorical\",\n",
    "        classes = CLASS_LIST,\n",
    "        subset = 'training'\n",
    "    )\n",
    "    val_dataset = imgdatagen.flow_from_dataframe(\n",
    "        dataframe = df,\n",
    "        directory = datasetdir,\n",
    "        x_col=\"filename\",\n",
    "        y_col=\"labels\",\n",
    "        target_size = IMG_SHAPE,\n",
    "        seed = 42,\n",
    "        shuffle = True,\n",
    "        batch_size = BATCH_SIZE,\n",
    "        class_mode=\"categorical\",\n",
    "        classes = CLASS_LIST,\n",
    "        subset = 'validation'\n",
    "    )\n",
    "\n",
    "\n",
    "    return train_dataset, val_dataset, \n",
    "\n",
    "# train_dataset, val_dataset = DataLoad((350,350), preprocessing=preprocess_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2383f50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done parsing through directories\n",
      "(289212, 3)\n",
      "                                 folder  \\\n",
      "165076  Leopard_Print_Longline_Cardigan   \n",
      "201983                Plaid_Shirt_Dress   \n",
      "228499          Shore_Girl_Cropped_Tank   \n",
      "74179                 Crochet_Mesh_Tank   \n",
      "180548        Metallic_Striped_Knit_Tee   \n",
      "146280       High-Waisted_Lounge_Shorts   \n",
      "263887        Tie-Dye_Longline_Cardigan   \n",
      "78477    Cutout-Back_Floral_Print_Dress   \n",
      "82698        Daydreamer_Crocheted_Dress   \n",
      "137284            Glitter_Bodycon_Dress   \n",
      "\n",
      "                                                filename            labels  \n",
      "165076  Leopard_Print_Longline_Cardigan/img_00000040.jpg        [Cardigan]  \n",
      "201983                Plaid_Shirt_Dress/img_00000056.jpg           [Dress]  \n",
      "228499          Shore_Girl_Cropped_Tank/img_00000040.jpg            [Tank]  \n",
      "74179                 Crochet_Mesh_Tank/img_00000018.jpg            [Tank]  \n",
      "180548        Metallic_Striped_Knit_Tee/img_00000009.jpg    [Striped, Tee]  \n",
      "146280       High-Waisted_Lounge_Shorts/img_00000035.jpg          [Shorts]  \n",
      "263887        Tie-Dye_Longline_Cardigan/img_00000033.jpg        [Cardigan]  \n",
      "78477    Cutout-Back_Floral_Print_Dress/img_00000053.jpg   [Floral, Dress]  \n",
      "82698        Daydreamer_Crocheted_Dress/img_00000019.jpg           [Dress]  \n",
      "137284            Glitter_Bodycon_Dress/img_00000071.jpg  [Bodycon, Dress]  \n",
      "Num classes #\n",
      "21\n",
      "Found 228237 validated image filenames belonging to 21 classes.\n",
      "Found 25359 validated image filenames belonging to 21 classes.\n",
      "<class 'keras.preprocessing.image.DataFrameIterator'>\n",
      "<class 'keras.preprocessing.image.DataFrameIterator'>\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 2. 1. 1. 1. 2. 1. 1. 1. 1. 1. 1. 2. 2. 3. 1. 1.\n",
      " 3. 1. 2. 2. 2. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 2. 1. 1. 1. 1. 2. 1. 1. 1. 1.]\n",
      "[ 7.  5. 17.  7.  3.  0.  1.  5.  2.  6.  3.  7.  4.  1.  4.  2.  2.  1.\n",
      "  0.  0.  1.]\n",
      "(64, 224, 224, 3)\n",
      "(64, 21)\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "\n",
    "# Create custom preproocessing routine\n",
    "\n",
    "\n",
    "train_dataset, val_dataset = DataLoad((224,224), preprocessing=preprocess_input)\n",
    "\n",
    "print(type(train_dataset))\n",
    "print(type(val_dataset))\n",
    "# print(train_dataset.shape())\n",
    "\n",
    "X_train, y_train = next(train_dataset)\n",
    "\n",
    "print(type(X_train))\n",
    "print(y_train[0])\n",
    "print(np.sum(y_train, axis=1))\n",
    "print(np.sum(y_train, axis=0))\n",
    "print(np.shape(X_train))\n",
    "print(np.shape(y_train))\n",
    "# print(y_train.shape())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76770cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_peek = y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be206065",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = keras.applications.vgg16\n",
    "conv_model = vgg16.VGG16(weights='imagenet', include_top=False)\n",
    "# conv_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5049c7b7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d62db8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                802848    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 21)                693       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,520,341\n",
      "Trainable params: 805,653\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_model = vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "for layer in conv_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# flatten the output of the convolutional part:\n",
    "# x = keras.layers.Dropout(0.25)(conv_model.output)\n",
    " \n",
    "x = keras.layers.Flatten()(conv_model.output)\n",
    "# three hidden layers}\n",
    "x = keras.layers.Dense(32, activation='relu')(x)\n",
    "# x = keras.layers.Dropout(0.5)(x)\n",
    "x = keras.layers.Dense(32, activation='relu')(x)\n",
    "# x = keras.layers.Dropout(0.5)(x)\n",
    "x = keras.layers.Dense(32, activation='relu')(x)\n",
    "# x = keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "# x = keras.layers.Dense(64, activation='relu')(x)\n",
    "# final softmax layer with 40 categories\n",
    "predictions = keras.layers.Dense(len(CLASS_LIST), activation = 'sigmoid')(x)\n",
    "# creating the full model:\n",
    "full_model = keras.models.Model(inputs=conv_model.input, outputs=predictions)\n",
    "full_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2c730b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85fcbe8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 8790317263064311798\n",
       " xla_global_id: -1,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 5762973696\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 15975444588622002591\n",
       " physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3060 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\"\n",
       " xla_global_id: 416903419]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configure run environment\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "device_lib.list_local_devices()\n",
    "# tf.config.list_physical_devices('CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bc31e9",
   "metadata": {},
   "source": [
    "# Categorical Cross Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c550aa68",
   "metadata": {},
   "source": [
    "## Weighted Binary Cross-Entropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3031fbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as tfb\n",
    "import numpy as np\n",
    "\n",
    "POS_WEIGHT = 2  # multiplier for positive targets, needs to be tuned\n",
    "\n",
    "def weighted_binary_crossentropy(target, output):\n",
    "    \"\"\"\n",
    "    Weighted binary crossentropy between an output tensor \n",
    "    and a target tensor. POS_WEIGHT is used as a multiplier \n",
    "    for the positive targets.\n",
    "\n",
    "    Combination of the following functions:\n",
    "    * keras.losses.binary_crossentropy\n",
    "    * keras.backend.tensorflow_backend.binary_crossentropy\n",
    "    * tf.nn.weighted_cross_entropy_with_logits\n",
    "    \"\"\"\n",
    "    # transform back to logits\n",
    "    _epsilon = tfb._to_tensor(tfb.epsilon(), output.dtype.base_dtype)\n",
    "    output = tf.clip_by_value(output, _epsilon, 1 - _epsilon)\n",
    "    output = tfb.log(output / (1 - output))\n",
    "    # compute weighted loss\n",
    "    loss = tf.nn.weighted_cross_entropy_with_logits(labels=target,\n",
    "                                                    logits=output,\n",
    "                                                    pos_weight=POS_WEIGHT)\n",
    "    return tf.reduce_mean(loss, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e5d9a0",
   "metadata": {},
   "source": [
    "### F1-Metric Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b850fb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "def f1(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return 1 - K.mean(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b556470a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/50\n",
      " 418/1500 [=======>......................] - ETA: 4:45 - loss: 0.4073 - acc: 0.3830 - categorical_crossentropy: 3.0164"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mUbuntu-20.04\\home\\mdc20\\repos\\personal\\project-fashion-finder\\model\\src\\ModelTraining3.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/model/src/ModelTraining3.ipynb#X24sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# from tf.keras.losses import BinaryCrossentropy\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/model/src/ModelTraining3.ipynb#X24sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/model/src/ModelTraining3.ipynb#X24sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m# cce = tf.keras.losses.CategoricalCrossentropy(reduction=tf.keras.losses.Reduction.SUM, from_logits=False)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/model/src/ModelTraining3.ipynb#X24sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m# bce = tf.keras.losses.binary_crossentropy\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/model/src/ModelTraining3.ipynb#X24sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/model/src/ModelTraining3.ipynb#X24sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m# bce = BinaryCrossentropy()\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/model/src/ModelTraining3.ipynb#X24sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     full_model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39mweighted_binary_crossentropy,\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/model/src/ModelTraining3.ipynb#X24sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m                     optimizer\u001b[39m=\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdamax(learning_rate\u001b[39m=\u001b[39mlearning_rate, beta_1 \u001b[39m=\u001b[39m \u001b[39m0.9\u001b[39m, beta_2\u001b[39m=\u001b[39m\u001b[39m0.99\u001b[39m),\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/model/src/ModelTraining3.ipynb#X24sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m                     metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39macc\u001b[39m\u001b[39m'\u001b[39m, tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mCategoricalCrossentropy()],\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/model/src/ModelTraining3.ipynb#X24sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m                     )\n\u001b[1;32m---> <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/model/src/ModelTraining3.ipynb#X24sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     history \u001b[39m=\u001b[39m full_model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/model/src/ModelTraining3.ipynb#X24sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     train_dataset, \n\u001b[0;32m     <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/model/src/ModelTraining3.ipynb#X24sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     validation_data \u001b[39m=\u001b[39;49m val_dataset,\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/model/src/ModelTraining3.ipynb#X24sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     workers\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/model/src/ModelTraining3.ipynb#X24sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/model/src/ModelTraining3.ipynb#X24sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     steps_per_epoch \u001b[39m=\u001b[39;49m \u001b[39m1500\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/model/src/ModelTraining3.ipynb#X24sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     validation_steps \u001b[39m=\u001b[39;49m \u001b[39m400\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/model/src/ModelTraining3.ipynb#X24sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[checkpoint]\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/model/src/ModelTraining3.ipynb#X24sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/model/src/ModelTraining3.ipynb#X24sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     histories\u001b[39m.\u001b[39mappend(history)\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/model/src/ModelTraining3.ipynb#X24sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(histories))\n",
      "File \u001b[1;32mc:\\Users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "import time\n",
    "histories = list()\n",
    "for learning_rate in [0.001]:\n",
    "\n",
    "    checkpoint = ModelCheckpoint(\"C:\\\\Users\\mdc20\\\\best_model_21_class_lr@\" + str(learning_rate) + \"-\" + str(time.time()) + \".hdf5\", monitor='loss', verbose=1,\n",
    "        save_best_only=True, mode='auto', period=1)\n",
    "# from tf.keras.losses import BinaryCrossentropy\n",
    "\n",
    "    # cce = tf.keras.losses.CategoricalCrossentropy(reduction=tf.keras.losses.Reduction.SUM, from_logits=False)\n",
    "    # bce = tf.keras.losses.binary_crossentropy\n",
    "\n",
    "    # bce = BinaryCrossentropy()\n",
    "    full_model.compile(loss='weighted_binary_crossentropy',\n",
    "                    optimizer=keras.optimizers.Adamax(learning_rate=learning_rate, beta_1 = 0.9, beta_2=0.99),\n",
    "                    metrics=['acc', tf.keras.metrics.CategoricalCrossentropy()],\n",
    "                    )\n",
    "    history = full_model.fit(\n",
    "    train_dataset, \n",
    "    validation_data = val_dataset,\n",
    "    workers=2,\n",
    "    epochs=50,\n",
    "    steps_per_epoch = 1500,\n",
    "    validation_steps = 400,\n",
    "    callbacks=[checkpoint]\n",
    "    )\n",
    "    histories.append(history)\n",
    "\n",
    "print(type(histories))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d278b0f9",
   "metadata": {},
   "source": [
    "## Restart training from kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b79ae4d",
   "metadata": {},
   "source": [
    "### Define saving routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "693ece64",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.002\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ab7fe55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "import time\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"C:\\\\Users\\mdc20\\\\best_model_21_class_lr@\" + str(LEARNING_RATE) + \"-\" + str(time.time()) + \".hdf5\", monitor='loss', verbose=1,\n",
    "        save_best_only=True, mode='auto', period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67d2f5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.2581 - acc: 0.5706WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 400 batches). You may need to use the repeat() function when building your dataset.\n",
      "\n",
      "Epoch 16: loss improved from inf to 0.25813, saving model to C:\\Users\\mdc20\\best_model_21_class_lr@0.002-1666761586.9275644.hdf5\n",
      "2000/2000 [==============================] - 1045s 522ms/step - loss: 0.2581 - acc: 0.5706 - val_loss: 0.2487 - val_acc: 0.5744\n",
      "Epoch 17/50\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.2563 - acc: 0.5728\n",
      "Epoch 17: loss improved from 0.25813 to 0.25633, saving model to C:\\Users\\mdc20\\best_model_21_class_lr@0.002-1666761586.9275644.hdf5\n",
      "2000/2000 [==============================] - 847s 423ms/step - loss: 0.2563 - acc: 0.5728\n",
      "Epoch 18/50\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.2547 - acc: 0.5761\n",
      "Epoch 18: loss improved from 0.25633 to 0.25475, saving model to C:\\Users\\mdc20\\best_model_21_class_lr@0.002-1666761586.9275644.hdf5\n",
      "2000/2000 [==============================] - 832s 416ms/step - loss: 0.2547 - acc: 0.5761\n",
      "Epoch 19/50\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.2532 - acc: 0.5824\n",
      "Epoch 19: loss improved from 0.25475 to 0.25316, saving model to C:\\Users\\mdc20\\best_model_21_class_lr@0.002-1666761586.9275644.hdf5\n",
      "2000/2000 [==============================] - 834s 417ms/step - loss: 0.2532 - acc: 0.5824\n",
      "Epoch 20/50\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.2520 - acc: 0.5845\n",
      "Epoch 20: loss improved from 0.25316 to 0.25199, saving model to C:\\Users\\mdc20\\best_model_21_class_lr@0.002-1666761586.9275644.hdf5\n",
      "2000/2000 [==============================] - 830s 415ms/step - loss: 0.2520 - acc: 0.5845\n",
      "Epoch 21/50\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.2507 - acc: 0.5874\n",
      "Epoch 21: loss improved from 0.25199 to 0.25069, saving model to C:\\Users\\mdc20\\best_model_21_class_lr@0.002-1666761586.9275644.hdf5\n",
      "2000/2000 [==============================] - 830s 415ms/step - loss: 0.2507 - acc: 0.5874\n",
      "Epoch 22/50\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.2493 - acc: 0.5891\n",
      "Epoch 22: loss improved from 0.25069 to 0.24927, saving model to C:\\Users\\mdc20\\best_model_21_class_lr@0.002-1666761586.9275644.hdf5\n",
      "2000/2000 [==============================] - 829s 415ms/step - loss: 0.2493 - acc: 0.5891\n",
      "Epoch 23/50\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.2496 - acc: 0.5910\n",
      "Epoch 23: loss did not improve from 0.24927\n",
      "2000/2000 [==============================] - 831s 415ms/step - loss: 0.2496 - acc: 0.5910\n",
      "Epoch 24/50\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.2489 - acc: 0.5912\n",
      "Epoch 24: loss improved from 0.24927 to 0.24891, saving model to C:\\Users\\mdc20\\best_model_21_class_lr@0.002-1666761586.9275644.hdf5\n",
      "2000/2000 [==============================] - 838s 419ms/step - loss: 0.2489 - acc: 0.5912\n",
      "Epoch 25/50\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.2476 - acc: 0.5947\n",
      "Epoch 25: loss improved from 0.24891 to 0.24756, saving model to C:\\Users\\mdc20\\best_model_21_class_lr@0.002-1666761586.9275644.hdf5\n",
      "2000/2000 [==============================] - 829s 414ms/step - loss: 0.2476 - acc: 0.5947\n",
      "Epoch 26/50\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.2479 - acc: 0.5938\n",
      "Epoch 26: loss did not improve from 0.24756\n",
      "2000/2000 [==============================] - 831s 416ms/step - loss: 0.2479 - acc: 0.5938\n",
      "Epoch 27/50\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.2461 - acc: 0.5964\n",
      "Epoch 27: loss improved from 0.24756 to 0.24608, saving model to C:\\Users\\mdc20\\best_model_21_class_lr@0.002-1666761586.9275644.hdf5\n",
      "2000/2000 [==============================] - 839s 420ms/step - loss: 0.2461 - acc: 0.5964\n",
      "Epoch 28/50\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.2457 - acc: 0.5987\n",
      "Epoch 28: loss improved from 0.24608 to 0.24567, saving model to C:\\Users\\mdc20\\best_model_21_class_lr@0.002-1666761586.9275644.hdf5\n",
      "2000/2000 [==============================] - 834s 417ms/step - loss: 0.2457 - acc: 0.5987\n",
      "Epoch 29/50\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.2455 - acc: 0.5981\n",
      "Epoch 29: loss improved from 0.24567 to 0.24549, saving model to C:\\Users\\mdc20\\best_model_21_class_lr@0.002-1666761586.9275644.hdf5\n",
      "2000/2000 [==============================] - 833s 416ms/step - loss: 0.2455 - acc: 0.5981\n",
      "Epoch 30/50\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.2447 - acc: 0.6001\n",
      "Epoch 30: loss improved from 0.24549 to 0.24466, saving model to C:\\Users\\mdc20\\best_model_21_class_lr@0.002-1666761586.9275644.hdf5\n",
      "2000/2000 [==============================] - 831s 416ms/step - loss: 0.2447 - acc: 0.6001\n",
      "Epoch 31/50\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.2444 - acc: 0.6003\n",
      "Epoch 31: loss improved from 0.24466 to 0.24438, saving model to C:\\Users\\mdc20\\best_model_21_class_lr@0.002-1666761586.9275644.hdf5\n",
      "2000/2000 [==============================] - 837s 418ms/step - loss: 0.2444 - acc: 0.6003\n",
      "Epoch 32/50\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.2443 - acc: 0.6004\n",
      "Epoch 32: loss improved from 0.24438 to 0.24431, saving model to C:\\Users\\mdc20\\best_model_21_class_lr@0.002-1666761586.9275644.hdf5\n",
      "2000/2000 [==============================] - 837s 419ms/step - loss: 0.2443 - acc: 0.6004\n",
      "Epoch 33/50\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.2436 - acc: 0.6013\n",
      "Epoch 33: loss improved from 0.24431 to 0.24361, saving model to C:\\Users\\mdc20\\best_model_21_class_lr@0.002-1666761586.9275644.hdf5\n",
      "2000/2000 [==============================] - 834s 417ms/step - loss: 0.2436 - acc: 0.6013\n",
      "Epoch 34/50\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.2427 - acc: 0.6022\n",
      "Epoch 34: loss improved from 0.24361 to 0.24268, saving model to C:\\Users\\mdc20\\best_model_21_class_lr@0.002-1666761586.9275644.hdf5\n",
      "2000/2000 [==============================] - 836s 418ms/step - loss: 0.2427 - acc: 0.6022\n",
      "Epoch 35/50\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.2426 - acc: 0.6045\n",
      "Epoch 35: loss improved from 0.24268 to 0.24262, saving model to C:\\Users\\mdc20\\best_model_21_class_lr@0.002-1666761586.9275644.hdf5\n",
      "2000/2000 [==============================] - 835s 417ms/step - loss: 0.2426 - acc: 0.6045\n",
      "Epoch 36/50\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.2427 - acc: 0.6031\n",
      "Epoch 36: loss did not improve from 0.24262\n",
      "2000/2000 [==============================] - 841s 421ms/step - loss: 0.2427 - acc: 0.6031\n",
      "Epoch 37/50\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.2417 - acc: 0.6053\n",
      "Epoch 37: loss improved from 0.24262 to 0.24167, saving model to C:\\Users\\mdc20\\best_model_21_class_lr@0.002-1666761586.9275644.hdf5\n",
      "2000/2000 [==============================] - 816s 408ms/step - loss: 0.2417 - acc: 0.6053\n",
      "Epoch 38/50\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.2423 - acc: 0.6035\n",
      "Epoch 38: loss did not improve from 0.24167\n",
      "2000/2000 [==============================] - 826s 413ms/step - loss: 0.2423 - acc: 0.6035\n",
      "Epoch 39/50\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.2417 - acc: 0.6070\n",
      "Epoch 39: loss improved from 0.24167 to 0.24166, saving model to C:\\Users\\mdc20\\best_model_21_class_lr@0.002-1666761586.9275644.hdf5\n",
      "2000/2000 [==============================] - 829s 414ms/step - loss: 0.2417 - acc: 0.6070\n",
      "Epoch 40/50\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.2416 - acc: 0.6053\n",
      "Epoch 40: loss improved from 0.24166 to 0.24156, saving model to C:\\Users\\mdc20\\best_model_21_class_lr@0.002-1666761586.9275644.hdf5\n",
      "2000/2000 [==============================] - 834s 417ms/step - loss: 0.2416 - acc: 0.6053\n",
      "Epoch 41/50\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.2411 - acc: 0.6072\n",
      "Epoch 41: loss improved from 0.24156 to 0.24112, saving model to C:\\Users\\mdc20\\best_model_21_class_lr@0.002-1666761586.9275644.hdf5\n",
      "2000/2000 [==============================] - 827s 413ms/step - loss: 0.2411 - acc: 0.6072\n",
      "Epoch 42/50\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.2409 - acc: 0.6072\n",
      "Epoch 42: loss improved from 0.24112 to 0.24087, saving model to C:\\Users\\mdc20\\best_model_21_class_lr@0.002-1666761586.9275644.hdf5\n",
      "2000/2000 [==============================] - 831s 415ms/step - loss: 0.2409 - acc: 0.6072\n",
      "Epoch 43/50\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.2407 - acc: 0.6069\n",
      "Epoch 43: loss improved from 0.24087 to 0.24066, saving model to C:\\Users\\mdc20\\best_model_21_class_lr@0.002-1666761586.9275644.hdf5\n",
      "2000/2000 [==============================] - 828s 414ms/step - loss: 0.2407 - acc: 0.6069\n",
      "Epoch 44/50\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.2403 - acc: 0.6081\n",
      "Epoch 44: loss improved from 0.24066 to 0.24026, saving model to C:\\Users\\mdc20\\best_model_21_class_lr@0.002-1666761586.9275644.hdf5\n",
      "2000/2000 [==============================] - 838s 419ms/step - loss: 0.2403 - acc: 0.6081\n",
      "Epoch 45/50\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.2410 - acc: 0.6074\n",
      "Epoch 45: loss did not improve from 0.24026\n",
      "2000/2000 [==============================] - 830s 415ms/step - loss: 0.2410 - acc: 0.6074\n",
      "Epoch 46/50\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.2398 - acc: 0.6094\n",
      "Epoch 46: loss improved from 0.24026 to 0.23980, saving model to C:\\Users\\mdc20\\best_model_21_class_lr@0.002-1666761586.9275644.hdf5\n",
      "2000/2000 [==============================] - 830s 415ms/step - loss: 0.2398 - acc: 0.6094\n",
      "Epoch 47/50\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.2389 - acc: 0.6109\n",
      "Epoch 47: loss improved from 0.23980 to 0.23891, saving model to C:\\Users\\mdc20\\best_model_21_class_lr@0.002-1666761586.9275644.hdf5\n",
      "2000/2000 [==============================] - 832s 416ms/step - loss: 0.2389 - acc: 0.6109\n",
      "Epoch 48/50\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.2393 - acc: 0.6096\n",
      "Epoch 48: loss did not improve from 0.23891\n",
      "2000/2000 [==============================] - 838s 419ms/step - loss: 0.2393 - acc: 0.6096\n",
      "Epoch 49/50\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.2386 - acc: 0.6116\n",
      "Epoch 49: loss improved from 0.23891 to 0.23859, saving model to C:\\Users\\mdc20\\best_model_21_class_lr@0.002-1666761586.9275644.hdf5\n",
      "2000/2000 [==============================] - 834s 417ms/step - loss: 0.2386 - acc: 0.6116\n",
      "Epoch 50/50\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.2401 - acc: 0.6092\n",
      "Epoch 50: loss did not improve from 0.23859\n",
      "2000/2000 [==============================] - 834s 417ms/step - loss: 0.2401 - acc: 0.6092\n"
     ]
    }
   ],
   "source": [
    "# Restart training\n",
    "EPOCH = 50\n",
    "\n",
    "MODEL_FOLDER_PATH = 'C:\\\\Users\\\\mdc20\\\\'\n",
    "MODEL_FILE = 'best_model_21_class_lr@0.001-1666709152.5078835.hdf5'\n",
    "MODEL_FILE = 'best_model_21_class_lr@0.002-1666761586.9275644.hdf5'\n",
    "\n",
    "restored_model = tf.keras.models.load_model(MODEL_FOLDER_PATH + MODEL_FILE, custom_objects={'weighted_binary_crossentropy': weighted_binary_crossentropy})\n",
    "# restored_model.add_loss()\n",
    "restored_model.compile(loss='binary_crossentropy',\n",
    "                    optimizer=keras.optimizers.Adamax(learning_rate=LEARNING_RATE, beta_1 = 0.9, beta_2=0.99),\n",
    "                    metrics=['acc'],\n",
    "                    )\n",
    "# tf.keras.backend.set_value(restored_model.optimizer.learning_rate, LEARNING_RATE)\n",
    "# tf.keras.backend.set_value(restored_model)\n",
    "history = restored_model.fit(\n",
    "    train_dataset, \n",
    "    validation_data = val_dataset,\n",
    "    workers=1,\n",
    "    epochs=100,\n",
    "    steps_per_epoch = 2000,\n",
    "    validation_steps = 400,\n",
    "    initial_epoch=EPOCH, \n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0bef5190",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\mdc20\\\\')\n",
    "full_model.save('test_kernel_21_class.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90b98a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdc20\n",
      "Epoch 1/10\n",
      "1991/1991 [==============================] - ETA: 0s - loss: 24.8112 - acc: 0.5546 - categorical_crossentropy: 24.8112\n",
      "Epoch 1: acc improved from -inf to 0.55458, saving model to best_model.hdf5\n",
      "1991/1991 [==============================] - 722s 362ms/step - loss: 24.8112 - acc: 0.5546 - categorical_crossentropy: 24.8112 - val_loss: 18.4811 - val_acc: 0.5966 - val_categorical_crossentropy: 18.4811\n",
      "Epoch 2/10\n",
      "1991/1991 [==============================] - ETA: 0s - loss: 26.5472 - acc: 0.5445 - categorical_crossentropy: 26.5472\n",
      "Epoch 2: acc did not improve from 0.55458\n",
      "1991/1991 [==============================] - 653s 328ms/step - loss: 26.5472 - acc: 0.5445 - categorical_crossentropy: 26.5472 - val_loss: 14.1841 - val_acc: 0.5125 - val_categorical_crossentropy: 14.1841\n",
      "Epoch 3/10\n",
      "1991/1991 [==============================] - ETA: 0s - loss: 34.2294 - acc: 0.5302 - categorical_crossentropy: 34.2294\n",
      "Epoch 3: acc did not improve from 0.55458\n",
      "1991/1991 [==============================] - 685s 344ms/step - loss: 34.2294 - acc: 0.5302 - categorical_crossentropy: 34.2294 - val_loss: 44.7962 - val_acc: 0.5584 - val_categorical_crossentropy: 44.7962\n",
      "Epoch 4/10\n",
      "1991/1991 [==============================] - ETA: 0s - loss: 46.5524 - acc: 0.5088 - categorical_crossentropy: 46.5524\n",
      "Epoch 4: acc did not improve from 0.55458\n",
      "1991/1991 [==============================] - 756s 379ms/step - loss: 46.5524 - acc: 0.5088 - categorical_crossentropy: 46.5524 - val_loss: 48.7954 - val_acc: 0.5348 - val_categorical_crossentropy: 48.7954\n",
      "Epoch 5/10\n",
      "1991/1991 [==============================] - ETA: 0s - loss: 62.9802 - acc: 0.4858 - categorical_crossentropy: 62.9802\n",
      "Epoch 5: acc did not improve from 0.55458\n",
      "1991/1991 [==============================] - 685s 343ms/step - loss: 62.9802 - acc: 0.4858 - categorical_crossentropy: 62.9802 - val_loss: 41.6054 - val_acc: 0.6428 - val_categorical_crossentropy: 41.6054\n",
      "Epoch 6/10\n",
      "1991/1991 [==============================] - ETA: 0s - loss: 80.4817 - acc: 0.4680 - categorical_crossentropy: 80.4817\n",
      "Epoch 6: acc did not improve from 0.55458\n",
      "1991/1991 [==============================] - 654s 329ms/step - loss: 80.4817 - acc: 0.4680 - categorical_crossentropy: 80.4817 - val_loss: 167.9760 - val_acc: 0.0849 - val_categorical_crossentropy: 167.9760\n",
      "Epoch 7/10\n",
      "1991/1991 [==============================] - ETA: 0s - loss: 106.0613 - acc: 0.4430 - categorical_crossentropy: 106.0613\n",
      "Epoch 7: acc did not improve from 0.55458\n",
      "1991/1991 [==============================] - 766s 384ms/step - loss: 106.0613 - acc: 0.4430 - categorical_crossentropy: 106.0613 - val_loss: 190.9534 - val_acc: 0.0868 - val_categorical_crossentropy: 190.9534\n",
      "Epoch 8/10\n",
      "1991/1991 [==============================] - ETA: 0s - loss: 136.6615 - acc: 0.4256 - categorical_crossentropy: 136.6615"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mUbuntu-20.04\\home\\mdc20\\repos\\personal\\project-fashion-finder\\ModelTraining2.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/ModelTraining2.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m os\u001b[39m.\u001b[39mchdir(\u001b[39m'\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mUsers\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mmdc20\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/ModelTraining2.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(os\u001b[39m.\u001b[39mgetcwd())\n\u001b[1;32m----> <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/ModelTraining2.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m history \u001b[39m=\u001b[39m full_model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/ModelTraining2.ipynb#X15sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     train_dataset, \n\u001b[0;32m      <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/ModelTraining2.ipynb#X15sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     validation_data \u001b[39m=\u001b[39;49m val_dataset,\n\u001b[0;32m      <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/ModelTraining2.ipynb#X15sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     workers\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/ModelTraining2.ipynb#X15sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/ModelTraining2.ipynb#X15sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[checkpoint]\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/ModelTraining2.ipynb#X15sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/ModelTraining2.ipynb#X15sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m plot_keras_history(history)\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/ModelTraining2.ipynb#X15sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m full_model\u001b[39m.\u001b[39msave(\u001b[39m'\u001b[39m\u001b[39mtype_kernel.keras_model\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages\\keras\\engine\\training.py:1606\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1591\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_eval_data_handler\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1592\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eval_data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39mget_data_handler(\n\u001b[0;32m   1593\u001b[0m         x\u001b[39m=\u001b[39mval_x,\n\u001b[0;32m   1594\u001b[0m         y\u001b[39m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1604\u001b[0m         steps_per_execution\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution,\n\u001b[0;32m   1605\u001b[0m     )\n\u001b[1;32m-> 1606\u001b[0m val_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(\n\u001b[0;32m   1607\u001b[0m     x\u001b[39m=\u001b[39;49mval_x,\n\u001b[0;32m   1608\u001b[0m     y\u001b[39m=\u001b[39;49mval_y,\n\u001b[0;32m   1609\u001b[0m     sample_weight\u001b[39m=\u001b[39;49mval_sample_weight,\n\u001b[0;32m   1610\u001b[0m     batch_size\u001b[39m=\u001b[39;49mvalidation_batch_size \u001b[39mor\u001b[39;49;00m batch_size,\n\u001b[0;32m   1611\u001b[0m     steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[0;32m   1612\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   1613\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   1614\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   1615\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   1616\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1617\u001b[0m     _use_cached_eval_dataset\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1618\u001b[0m )\n\u001b[0;32m   1619\u001b[0m val_logs \u001b[39m=\u001b[39m {\n\u001b[0;32m   1620\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mval_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name: val \u001b[39mfor\u001b[39;00m name, val \u001b[39min\u001b[39;00m val_logs\u001b[39m.\u001b[39mitems()\n\u001b[0;32m   1621\u001b[0m }\n\u001b[0;32m   1622\u001b[0m epoch_logs\u001b[39m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[1;32mc:\\Users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages\\keras\\engine\\training.py:1947\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1943\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1944\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m, step_num\u001b[39m=\u001b[39mstep, _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m   1945\u001b[0m ):\n\u001b[0;32m   1946\u001b[0m     callbacks\u001b[39m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m-> 1947\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtest_function(iterator)\n\u001b[0;32m   1948\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1949\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    952\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    953\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 954\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    955\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    956\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    957\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from plot_keras_history import show_history, plot_history\n",
    "import os\n",
    "os.chdir('C:\\\\Users\\\\mdc20\\\\')\n",
    "print(os.getcwd())\n",
    "\n",
    "\n",
    "\n",
    "plot_keras_history(history)\n",
    "\n",
    "full_model.save('type_kernel.keras_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e44556e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history3 = full_model.fit(\n",
    "    train_dataset, \n",
    "    validation_data = val_dataset,\n",
    "    workers=1,\n",
    "    epochs=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b083926c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b172830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_model.save('sparse_categorical_cross_entropy.h5')\n",
    "full_model.save('39_acc.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d390f2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('cat_cross_entropy_16_classes.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b23d6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "x_val, y_val = next(val_dataset)\n",
    "y_prediction = model.predict(x_val)\n",
    "print(y_prediction[2])\n",
    "print(y_val[2])\n",
    "print(np.shape(y_prediction))\n",
    "# preds = np.argmax(y_prediction, axis=1)\n",
    "# print(preds)\n",
    "\n",
    "k = 4\n",
    "axis = 1 # Search for top k values in row\n",
    "top_k_indx = np.argpartition(y_prediction, -4, axis=axis)[-4:].T\n",
    "print(top_k_indx)\n",
    "print(np.shape(top_k_indx))\n",
    "# result = confusion_matrix(y_val, y_prediction, normalize='y_pred=')\n",
    "# print(y_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8302f478",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('gpu3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "b689eaeee660c5f4e77cc22f066091ae7dcd8b72ca1cd0b8aadc4281bbfd7404"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
