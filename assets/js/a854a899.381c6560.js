"use strict";(self.webpackChunktu_cis_4398_docs_template=self.webpackChunktu_cis_4398_docs_template||[]).push([[3196],{3905:function(e,t,n){n.d(t,{Zo:function(){return c},kt:function(){return u}});var a=n(67294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},r=Object.keys(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var l=a.createContext({}),d=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},c=function(e){var t=d(e.components);return a.createElement(l.Provider,{value:t},e.children)},p={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},m=a.forwardRef((function(e,t){var n=e.components,o=e.mdxType,r=e.originalType,l=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),m=d(n),u=o,h=m["".concat(l,".").concat(u)]||m[u]||p[u]||r;return n?a.createElement(h,i(i({ref:t},c),{},{components:n})):a.createElement(h,i({ref:t},c))}));function u(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var r=n.length,i=new Array(r);i[0]=m;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:o,i[1]=s;for(var d=2;d<r;d++)i[d]=n[d];return a.createElement.apply(null,i)}return a.createElement.apply(null,n)}m.displayName="MDXCreateElement"},21317:function(e,t,n){n.r(t),n.d(t,{assets:function(){return c},contentTitle:function(){return l},default:function(){return u},frontMatter:function(){return s},metadata:function(){return d},toc:function(){return p}});var a=n(83117),o=n(80102),r=(n(67294),n(3905)),i=["components"],s={sidebar_position:1},l="System Overview",d={unversionedId:"requirements/system-overview",id:"requirements/system-overview",title:"System Overview",description:"Project Abstract",source:"@site/docs/requirements/system-overview.md",sourceDirName:"requirements",slug:"/requirements/system-overview",permalink:"/project-fashion-finder/docs/requirements/system-overview",draft:!1,editUrl:"https://github.com/Capstone-Projects-2022-Fall/project-fashion-finder/edit/main/documentation/docs/requirements/system-overview.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_position:1},sidebar:"docsSidebar",previous:{title:"Requirements Specification",permalink:"/project-fashion-finder/docs/category/requirements-specification"},next:{title:"System Block Diagram",permalink:"/project-fashion-finder/docs/requirements/system-block-diagram"}},c={},p=[{value:"Project Abstract",id:"project-abstract",level:2},{value:"Data Requirements",id:"data-requirements",level:2},{value:"Data Cleaning process",id:"data-cleaning-process",level:3},{value:"Model Training",id:"model-training",level:2},{value:"Model Deployment Process",id:"model-deployment-process",level:2},{value:"Front-End Development",id:"front-end-development",level:2},{value:"Back-End Development",id:"back-end-development",level:2},{value:"Models",id:"models",level:3},{value:"Like",id:"like",level:4},{value:"UserFashionPiece",id:"userfashionpiece",level:4},{value:"Background",id:"background",level:2}],m={toc:p};function u(e){var t=e.components,s=(0,o.Z)(e,i);return(0,r.kt)("wrapper",(0,a.Z)({},m,s,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"system-overview"},"System Overview"),(0,r.kt)("h2",{id:"project-abstract"},"Project Abstract"),(0,r.kt)("p",null,"The Fashion Finder Web App will be an application for identifying pieces of clothing and gaining inspiration for outfits and fashion pieces. It serves as a multi-tool for users to find fashion pieces that fit their style and existing wardrobe."),(0,r.kt)("p",null,"The Features of the Fashion Finder web app can be found in the ",(0,r.kt)("a",{parentName:"p",href:"/project-fashion-finder/docs/requirements/features-and-requirements"},"Features and Requirements Document"),". This document will instead cover the main architectural hurdles that are required to get to the features described above."),(0,r.kt)("h2",{id:"data-requirements"},"Data Requirements"),(0,r.kt)("p",null,"In order to get a model that would generalize well, a lot of data was necessary. The training set (Deep Fashion) consists of 30 GB of high resolution image data, containing a wide variety of images obtained from retailers, marketers, and photo collections. All of these files had brief descriptors."),(0,r.kt)("h1",{id:"conceptual-design"},"Conceptual Design"),(0,r.kt)("h3",{id:"data-cleaning-process"},"Data Cleaning process"),(0,r.kt)("p",null,"A data cleaning system will prepare the raw data from Deep Fashion (our training set) and the VGG 16 model."),(0,r.kt)("p",null,"Of all of the classes present in the data, we selected a subset of classes capable of having strong predictive power."),(0,r.kt)("p",null,"The inputted data was filtered to train only on items which fit in at least one of the classes below"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},'CLASS_LIST = ["Tee","Tank","Dress","Shorts","Skirt","Hoodie","Jumpsuit","Sweater","Blazer","Striped","Cardigan","Blouse","Jacket","Jeans","Maxi","Floral","Denim","Sweatshorts","Polka","Shawl","Bodycon"]\n')),(0,r.kt)("h2",{id:"model-training"},"Model Training"),(0,r.kt)("p",null,"The code for the model training can be found here ",(0,r.kt)("a",{target:"_blank",href:n(62549).Z},"here"),".\nA Data Loader utility is used to batch process image files alongside their labels and feed them into the neural network. The neural network takes in batches of 32 images at a time, guess a prediction, and then use backpropogatation ot update model weights. The best model training took 72 hours and involved 50 batches over 20 samples of the data. It achieved an accuracy of score of 84% on a class list size of 14. The model that is actually deployed achieved a sample-weighted accuracy of 79% on a class list size of 21. Given the quantity of data and lack of time for manual data cleansing, these are high accuracy scores."),(0,r.kt)("h2",{id:"model-deployment-process"},"Model Deployment Process"),(0,r.kt)("p",null,"In order for the machine learning microservice to be deployed it had to be hosted by Django. Instead of making it part of the django web-app, it is deployed as a separate app, named ",(0,r.kt)("inlineCode",{parentName:"p"},"ImgPredMicroservice"),". This means that it does not share the same thread as the web server and does not risk hanging the web server when it needs to make heavy calculations. "),(0,r.kt)("p",null,"The model is loaded once when the web server starts. To actually process newly uploaded data, routines were written to read a file from Django's ",(0,r.kt)("inlineCode",{parentName:"p"},"InMemoryUploadedFile")," data type and transform it into a 2D RGB-valued array. With the new array of shape (m,n,3), it can be inputted into the trained model and receive labels back."),(0,r.kt)("h2",{id:"front-end-development"},"Front-End Development"),(0,r.kt)("p",null,"Using the package manager npm@18, front-end components are written in react, compiled as javascript, and then served as static files by the Django file server."),(0,r.kt)("h2",{id:"back-end-development"},"Back-End Development"),(0,r.kt)("p",null,"Back-end development occurs in three different areas."),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"CRUD operations for users items"),(0,r.kt)("li",{parentName:"ol"},"Data transformation and Machine learning algorthms"),(0,r.kt)("li",{parentName:"ol"},"Storage and retrieval of images")),(0,r.kt)("p",null,"In (1), most routes represent the creation, retrieval, and deletion of models described below.\nIn (2), most routes depend on the core instantiation of the ",(0,r.kt)("inlineCode",{parentName:"p"},"model")," variable, which is read in from ",(0,r.kt)("inlineCode",{parentName:"p"},"src/model/artifacts/")," when the webserver is booted.\nIn (3), most routines will make use of in-memory representations of images, and when they need to be stored permanently, they will be stored in MongoDB."),(0,r.kt)("h3",{id:"models"},"Models"),(0,r.kt)("h4",{id:"like"},"Like"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"    user_id::str (ref to django user id)\n    user_name::str (ref to django user name)\n    fashion_piece::ObjectID (ref to piece from `LabeledFashionPiece` collection)\n  User\n    id, username, fname, lname, hashed_password\n")),(0,r.kt)("h4",{id:"userfashionpiece"},"UserFashionPiece"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"descriptor::str (Description)\nhex_codes::List[List[int]] Hex codes for palette\nrgb::List[List[int]] RGB representations of pallete\nlabels::List[str] List of labels provided by machine learning kernel.\n")),(0,r.kt)("h2",{id:"background"},"Background"),(0,r.kt)("p",null,"While there are lots of different fashion sites out that let users upload photos and share that data, Fashion Finder distinguishes itself from those sites by running machine learning algorithms, color detection algorithms, and customized recommendation algorithms to give users more of what they want. Sites like pinterest allow users to somewhat customize their feed, but they only give feedback on existing content. "),(0,r.kt)("h1",{id:"conceptual-design-1"},"Conceptual Design"),(0,r.kt)("p",null," This progressive web application will be developed with the purpose of being used on Android or Google mobile devices. The back-end API will be a Django REST API. It will handle modeling the relevant data and the needed CRUD operations. The Django REST API will be integrated with MongoDB by making use of the pymongo driver. Linked are examples of using MongoDB with Django:\n\u25cb\t",(0,r.kt)("a",{parentName:"p",href:"https://www.mongodb.com/compatibility/mongodb-and-django"},"https://www.mongodb.com/compatibility/mongodb-and-django"),"\n\u25cb\t",(0,r.kt)("a",{parentName:"p",href:"https://github.com/mongodb-developer/django-pymongo"},"https://github.com/mongodb-developer/django-pymongo"),'\nThe MongoDB database will be hosted via the MongoDB Atlas service and its schema will be controlled by Django.\nWe will be using VGG16 and Tensorflow to recognize and categorize clothing items as well as label the data. We will also use Scikit learn\u2019s K-nearest-neighbor algorithm to generate a similarity score and provide the final recommendation. The design of our user interface will have two main pages. The "Home" page, and the "Discover" page. The home page will serve as a place for users to get recommendations, and the discover page will serve as a place for users to indicate to the site their style preferences by "Liking" or "Disliking" items.'))}u.isMDXComponent=!0},62549:function(e,t,n){t.Z=n.p+"assets/files/ModelTraining3-48a5778b7ca8001680e05ddeee447f7c.ipynb"}}]);