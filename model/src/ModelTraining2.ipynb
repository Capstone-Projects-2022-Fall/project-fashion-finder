{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0975143c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "43\n",
      "43\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas | wc -l\n",
    "!pip install tensorflow | wc -l\n",
    "!pip install tensorflow-gpu | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c63170b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\\\\\wsl.localhost\\\\Ubuntu-20.04\\\\home\\\\mdc20\\\\repos\\\\personal\\\\project-fashion-finder'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1a01073",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_LIST = [\"Tee\",\"Tank\",\"Dress\",\"Shorts\",\"Skirt\",\"Jumpsuit\",\"Sweater\",\"Blazer\",\"Striped\",\"Cardigan\",\"Blouse\",\"Romper\",\"Sweatpants\",\"Jacket\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy\n",
    "import PIL\n",
    "PIL.Image.MAX_IMAGE_PIXELS = None\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "tf.compat.v1.keras.backend.set_session(tf.compat.v1.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "af8ec586",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "datasetdir = 'C:\\\\Users\\\\mdc20\\\\Downloads\\\\img'\n",
    "os.chdir(datasetdir)\n",
    "def constructImageClassDataFrame(shape, min_class_occurence = 1, class_list = CLASS_LIST):\n",
    "    # Args: \n",
    "    #   Shape: Image shape (2D)\n",
    "    #   min_class_occurence: number of times class must occur in labeled dir in order to add it to the final sclass list\n",
    "    \n",
    "    \n",
    "    sub_dirs = [d for d in os.listdir(os.getcwd()) if os.path.isdir(os.path.join(datasetdir, d))]\n",
    "    \n",
    "    if class_list is None:\n",
    "        classes = defaultdict(lambda: 0)\n",
    "\n",
    "        for sub_dir in sub_dirs:\n",
    "            labels = sub_dir.split('_')\n",
    "            for label in labels:\n",
    "                classes[label] += 1\n",
    "        top_k_classes = [cls for cls in classes if classes[cls] >= min_class_occurence]\n",
    "        label_classes = top_k_classes    \n",
    "    else:\n",
    "        classes = class_list\n",
    "        label_classes = classes\n",
    "\n",
    "    \n",
    "    # classes = list(classes)\n",
    "    # print(\"Done calculating list of classes\")\n",
    "\n",
    "    # TODO: remove\n",
    "    # top_k_classes = ['Graphic', 'Tee', 'Tank', 'Dress', 'Shorts', 'Print', 'Skirt', 'Blouse', 'Top', 'Leggings', 'Sweater', 'Abstract', 'Romper', 'Jumpsuit', 'Floral', 'Cardigan',  'Stripe', 'Boxy','Joggers', 'Striped',  'Tribal', 'Jacket', 'Jeans' ]\n",
    "    # top_k_classes = ['Top', 'Blouse']\n",
    "\n",
    "    arr = [[labeled_dir, file] for labeled_dir in sub_dirs for file in os.listdir(labeled_dir) ]\n",
    "    print(\"Done parsing through directories\")\n",
    "    df = pd.DataFrame(data=arr, columns=[\"folder\",\"filename\"])\n",
    "\n",
    "\n",
    "\n",
    "    df['filename'] = df['folder'] + '/' + df['filename']\n",
    "    df['labels'] = df['folder'].apply(lambda x : [y for y in x.split('_') if y in label_classes] if len([y for y in x.split('_') if y in label_classes]) > 0 else None)\n",
    "\n",
    "    print(np.shape(df))\n",
    "    # index_names = df [df['labels'] == []].index\n",
    "    # Drop Dataframe if none of its labels are present in the selected classes\n",
    "    df = df[df.labels.notnull()]\n",
    "\n",
    "    # series_list = list()\n",
    "    # print(\"Creating OHE for classes\")\n",
    "    # for idx, cls in enumerate(classes):\n",
    "    #     if idx %50 == 0: print(idx)\n",
    "    #     series = df['filename'].apply(lambda x: 1 if cls in x else 0)\n",
    "    #     series_list.append(series)\n",
    "    #     # df[str(cls)] = 1 if df['folder'].str.contains(str(cls)) else 0\n",
    "    \n",
    "    # df = pd.concat([df, series_list], axis=1)\n",
    "\n",
    "    #     files = os.listdir(labeled_dir)\n",
    "    #     labels = labeled_dir.split(\"_\")\n",
    "    #     for file in files:\n",
    "    #         continue\n",
    "            # df.loc[len(df.index)] = [os.path.join(datasetdir, labeled_dir), labels]\n",
    "\n",
    "    \n",
    "    # df.head()\n",
    "\n",
    "    return df\n",
    "\n",
    "# df, top_k_classes = constructImageClassDataFrame(shape = (256,256), min_class_occurence=10,class_list=['Shirt','Shorts'])\n",
    "# print(df.head(100))\n",
    "# print(np.shape(df))\n",
    "# print(top_k_classes)\n",
    "# print(np.shape(top_k_classes))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9523a500",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetdir = 'E:\\\\img_highres'\n",
    "os.chdir(datasetdir)\n",
    "\n",
    "from msilib.schema import Directory\n",
    "from random import shuffle\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "BATCH_SIZE = 8\n",
    "IMG_SHAPE = (512,512)\n",
    "\n",
    "\n",
    "def DataLoad(shape, preprocessing): \n",
    "    '''Create the training and validation datasets for \n",
    "    a given image shape.\n",
    "    '''\n",
    "    imgdatagen = ImageDataGenerator(\n",
    "        preprocessing_function = preprocessing,\n",
    "        horizontal_flip = True, \n",
    "        validation_split = 0.1,\n",
    "        rescale = 1.0/255, \n",
    "    )\n",
    "\n",
    "    height, width = shape\n",
    "\n",
    "    df = constructImageClassDataFrame(shape, class_list=CLASS_LIST)\n",
    "\n",
    "    print(df.sample(n=10))\n",
    "    # Modify dataframe to only take images with references to classes\n",
    "\n",
    "    print(\"Num classes #\")\n",
    "    print(len(CLASS_LIST)) \n",
    "    # for subdir\n",
    "\n",
    "    train_dataset = imgdatagen.flow_from_dataframe(\n",
    "        dataframe = df,\n",
    "        directory = datasetdir,\n",
    "        x_col=\"filename\",\n",
    "        y_col=\"labels\",\n",
    "        target_size = IMG_SHAPE,\n",
    "        seed = 42,\n",
    "        shuffle = True,\n",
    "        batch_size = BATCH_SIZE,\n",
    "        class_mode=\"categorical\",\n",
    "        classes = CLASS_LIST,\n",
    "        subset = 'training'\n",
    "    )\n",
    "    val_dataset = imgdatagen.flow_from_dataframe(\n",
    "        dataframe = df,\n",
    "        directory = datasetdir,\n",
    "        x_col=\"filename\",\n",
    "        y_col=\"labels\",\n",
    "        target_size = IMG_SHAPE,\n",
    "        seed = 42,\n",
    "        shuffle = True,\n",
    "        batch_size = BATCH_SIZE,\n",
    "        class_mode=\"categorical\",\n",
    "        classes = CLASS_LIST,\n",
    "        subset = 'validation'\n",
    "    )\n",
    "\n",
    "\n",
    "    return train_dataset, val_dataset, \n",
    "\n",
    "# train_dataset, val_dataset = DataLoad((350,350), preprocessing=preprocess_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2383f50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done parsing through directories\n",
      "(289212, 3)\n",
      "                                 folder  \\\n",
      "249921           Striped_Raglan_Sweater   \n",
      "275194         Two-Tone_Chunky_Cardigan   \n",
      "45699         Chiffon_Halter_Maxi_Dress   \n",
      "151256    Island_Tropics_Buttoned_Dress   \n",
      "273785           Tuxedo-Inspired_Blazer   \n",
      "187977                          NYC_Tee   \n",
      "105222  EPTM._Tribal_Print_Track_Jacket   \n",
      "232356   Slub_Knit_Buttoned-Back_Blouse   \n",
      "196047         Paisley_Print_Maxi_Dress   \n",
      "50569              Classic_Denim_Shorts   \n",
      "\n",
      "                                                filename              labels  \n",
      "249921           Striped_Raglan_Sweater/img_00000041.jpg  [Striped, Sweater]  \n",
      "275194         Two-Tone_Chunky_Cardigan/img_00000017.jpg          [Cardigan]  \n",
      "45699         Chiffon_Halter_Maxi_Dress/img_00000008.jpg             [Dress]  \n",
      "151256    Island_Tropics_Buttoned_Dress/img_00000043.jpg             [Dress]  \n",
      "273785           Tuxedo-Inspired_Blazer/img_00000133.jpg            [Blazer]  \n",
      "187977                          NYC_Tee/img_00000082.jpg               [Tee]  \n",
      "105222  EPTM._Tribal_Print_Track_Jacket/img_00000017.jpg            [Jacket]  \n",
      "232356   Slub_Knit_Buttoned-Back_Blouse/img_00000062.jpg            [Blouse]  \n",
      "196047         Paisley_Print_Maxi_Dress/img_00000011.jpg             [Dress]  \n",
      "50569              Classic_Denim_Shorts/img_00000026.jpg            [Shorts]  \n",
      "Num classes #\n",
      "14\n",
      "Found 221751 validated image filenames belonging to 14 classes.\n",
      "Found 24638 validated image filenames belonging to 14 classes.\n",
      "<class 'keras.preprocessing.image.DataFrameIterator'>\n",
      "<class 'keras.preprocessing.image.DataFrameIterator'>\n",
      "<class 'numpy.ndarray'>\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 1. 1. 1. 1. 2. 1. 1.]\n",
      "[2. 0. 3. 2. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "(8, 512, 512, 3)\n",
      "(8, 14)\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "\n",
    "# Create custom preproocessing routine\n",
    "\n",
    "\n",
    "train_dataset, val_dataset = DataLoad((512,512), preprocessing=preprocess_input)\n",
    "\n",
    "print(type(train_dataset))\n",
    "print(type(val_dataset))\n",
    "# print(train_dataset.shape())\n",
    "\n",
    "X_train, y_train = next(train_dataset)\n",
    "\n",
    "print(type(X_train))\n",
    "print(y_train[0])\n",
    "print(np.sum(y_train, axis=1))\n",
    "print(np.sum(y_train, axis=0))\n",
    "print(np.shape(X_train))\n",
    "print(np.shape(y_train))\n",
    "# print(y_train.shape())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "76770cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_peek = y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "be206065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_15 (InputLayer)       [(None, None, None, 3)]   0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, None, None, 64)    1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, None, None, 64)    36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, None, None, 128)   73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, None, None, 128)   147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, None, None, 128)   0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, None, None, 256)   295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, None, None, 256)   590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, None, None, 256)   590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, None, None, 256)   0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, None, None, 512)   1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16 = keras.applications.vgg16\n",
    "conv_model = vgg16.VGG16(weights='imagenet', include_top=False)\n",
    "conv_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5049c7b7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4d62db8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_16 (InputLayer)       [(None, 512, 512, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 512, 512, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 512, 512, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 256, 256, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 256, 256, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 256, 256, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 128, 128, 128)     0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 128, 128, 256)     295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 128, 128, 256)     590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 128, 128, 256)     590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 64, 64, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 64, 64, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 64, 64, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 64, 64, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 32, 32, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 16, 16, 512)       0         \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 131072)            0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 20)                2621460   \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 20)                420       \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 20)                420       \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 14)                294       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,337,282\n",
      "Trainable params: 2,622,594\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_model = vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(512,512,3))\n",
    "\n",
    "# flatten the output of the convolutional part: \n",
    "x = keras.layers.Flatten()(conv_model.output)\n",
    "# three hidden layers}\n",
    "x = keras.layers.Dense(20, activation='relu')(x)\n",
    "x = keras.layers.Dense(20, activation='relu')(x)\n",
    "x = keras.layers.Dense(20, activation='relu')(x)\n",
    "# final softmax layer with 40 categories\n",
    "\n",
    "predictions = keras.layers.Dense(14, activation = 'sigmoid')(x)\n",
    "for layer in conv_model.layers:\n",
    "    layer.trainable = False\n",
    "# creating the full model:\n",
    "full_model = keras.models.Model(inputs=conv_model.input, outputs=predictions)\n",
    "full_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2c730b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "85fcbe8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 18228482594933148473\n",
       " xla_global_id: -1,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 5230841856\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 8765513986292396532\n",
       " physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3060 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\"\n",
       " xla_global_id: 416903419]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configure run environment\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "device_lib.list_local_devices()\n",
    "# tf.config.list_physical_devices('CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bc31e9",
   "metadata": {},
   "source": [
    "# Categorical Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b556470a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/20\n",
      "27719/27719 [==============================] - ETA: 0s - loss: 0.1849 - acc: 0.4879 - categorical_crossentropy: 1.8243\n",
      "Epoch 1: val_acc improved from -inf to 0.54217, saving model to C:\\Users\\mdc20\\best_model_14_class_lr@0.0001-1665971573.2646348.hdf5\n",
      "27719/27719 [==============================] - 6303s 227ms/step - loss: 0.1849 - acc: 0.4879 - categorical_crossentropy: 1.8243 - val_loss: 0.1627 - val_acc: 0.5422 - val_categorical_crossentropy: 1.5722\n",
      "Epoch 2/20\n",
      "27719/27719 [==============================] - ETA: 0s - loss: 0.1608 - acc: 0.5601 - categorical_crossentropy: 1.5919\n",
      "Epoch 2: val_acc improved from 0.54217 to 0.57156, saving model to C:\\Users\\mdc20\\best_model_14_class_lr@0.0001-1665971573.2646348.hdf5\n",
      "27719/27719 [==============================] - 3729s 135ms/step - loss: 0.1608 - acc: 0.5601 - categorical_crossentropy: 1.5919 - val_loss: 0.1522 - val_acc: 0.5716 - val_categorical_crossentropy: 1.4717\n",
      "Epoch 3/20\n",
      "27719/27719 [==============================] - ETA: 0s - loss: 0.1538 - acc: 0.5820 - categorical_crossentropy: 1.5286\n",
      "Epoch 3: val_acc improved from 0.57156 to 0.58256, saving model to C:\\Users\\mdc20\\best_model_14_class_lr@0.0001-1665971573.2646348.hdf5\n",
      "27719/27719 [==============================] - 3827s 138ms/step - loss: 0.1538 - acc: 0.5820 - categorical_crossentropy: 1.5286 - val_loss: 0.1501 - val_acc: 0.5826 - val_categorical_crossentropy: 1.4870\n",
      "Epoch 4/20\n",
      "27719/27719 [==============================] - ETA: 0s - loss: 0.1493 - acc: 0.5966 - categorical_crossentropy: 1.4887\n",
      "Epoch 4: val_acc improved from 0.58256 to 0.58349, saving model to C:\\Users\\mdc20\\best_model_14_class_lr@0.0001-1665971573.2646348.hdf5\n",
      "27719/27719 [==============================] - 3825s 138ms/step - loss: 0.1493 - acc: 0.5966 - categorical_crossentropy: 1.4887 - val_loss: 0.1513 - val_acc: 0.5835 - val_categorical_crossentropy: 1.5108\n",
      "Epoch 5/20\n",
      "27719/27719 [==============================] - ETA: 0s - loss: 0.1457 - acc: 0.6083 - categorical_crossentropy: 1.4560\n",
      "Epoch 5: val_acc improved from 0.58349 to 0.59404, saving model to C:\\Users\\mdc20\\best_model_14_class_lr@0.0001-1665971573.2646348.hdf5\n",
      "27719/27719 [==============================] - 3710s 134ms/step - loss: 0.1457 - acc: 0.6083 - categorical_crossentropy: 1.4560 - val_loss: 0.1482 - val_acc: 0.5940 - val_categorical_crossentropy: 1.4753\n",
      "Epoch 6/20\n",
      "27719/27719 [==============================] - ETA: 0s - loss: 0.1430 - acc: 0.6169 - categorical_crossentropy: 1.4283\n",
      "Epoch 6: val_acc improved from 0.59404 to 0.60058, saving model to C:\\Users\\mdc20\\best_model_14_class_lr@0.0001-1665971573.2646348.hdf5\n",
      "27719/27719 [==============================] - 3562s 129ms/step - loss: 0.1430 - acc: 0.6169 - categorical_crossentropy: 1.4283 - val_loss: 0.1460 - val_acc: 0.6006 - val_categorical_crossentropy: 1.4599\n",
      "Epoch 7/20\n",
      "27719/27719 [==============================] - ETA: 0s - loss: 0.1407 - acc: 0.6253 - categorical_crossentropy: 1.4065\n",
      "Epoch 7: val_acc improved from 0.60058 to 0.60524, saving model to C:\\Users\\mdc20\\best_model_14_class_lr@0.0001-1665971573.2646348.hdf5\n",
      "27719/27719 [==============================] - 3565s 129ms/step - loss: 0.1407 - acc: 0.6253 - categorical_crossentropy: 1.4065 - val_loss: 0.1445 - val_acc: 0.6052 - val_categorical_crossentropy: 1.4500\n",
      "Epoch 8/20\n",
      "27719/27719 [==============================] - ETA: 0s - loss: 0.1387 - acc: 0.6324 - categorical_crossentropy: 1.3874\n",
      "Epoch 8: val_acc improved from 0.60524 to 0.60971, saving model to C:\\Users\\mdc20\\best_model_14_class_lr@0.0001-1665971573.2646348.hdf5\n",
      "27719/27719 [==============================] - 3566s 129ms/step - loss: 0.1387 - acc: 0.6324 - categorical_crossentropy: 1.3874 - val_loss: 0.1438 - val_acc: 0.6097 - val_categorical_crossentropy: 1.4274\n",
      "Epoch 9/20\n",
      "27719/27719 [==============================] - ETA: 0s - loss: 0.1370 - acc: 0.6385 - categorical_crossentropy: 1.3714\n",
      "Epoch 9: val_acc did not improve from 0.60971\n",
      "27719/27719 [==============================] - 3566s 129ms/step - loss: 0.1370 - acc: 0.6385 - categorical_crossentropy: 1.3714 - val_loss: 0.1481 - val_acc: 0.6053 - val_categorical_crossentropy: 1.5494\n",
      "Epoch 10/20\n",
      "27719/27719 [==============================] - ETA: 0s - loss: 0.1355 - acc: 0.6424 - categorical_crossentropy: 1.3580\n",
      "Epoch 10: val_acc did not improve from 0.60971\n",
      "27719/27719 [==============================] - 3560s 128ms/step - loss: 0.1355 - acc: 0.6424 - categorical_crossentropy: 1.3580 - val_loss: 0.1465 - val_acc: 0.6067 - val_categorical_crossentropy: 1.4641\n",
      "Epoch 11/20\n",
      "27719/27719 [==============================] - ETA: 0s - loss: 0.1342 - acc: 0.6474 - categorical_crossentropy: 1.3464\n",
      "Epoch 11: val_acc improved from 0.60971 to 0.61166, saving model to C:\\Users\\mdc20\\best_model_14_class_lr@0.0001-1665971573.2646348.hdf5\n",
      "27719/27719 [==============================] - 3571s 129ms/step - loss: 0.1342 - acc: 0.6474 - categorical_crossentropy: 1.3464 - val_loss: 0.1447 - val_acc: 0.6117 - val_categorical_crossentropy: 1.4478\n",
      "Epoch 12/20\n",
      "27719/27719 [==============================] - ETA: 0s - loss: 0.1331 - acc: 0.6525 - categorical_crossentropy: 1.3355\n",
      "Epoch 12: val_acc did not improve from 0.61166\n",
      "27719/27719 [==============================] - 3555s 128ms/step - loss: 0.1331 - acc: 0.6525 - categorical_crossentropy: 1.3355 - val_loss: 0.1531 - val_acc: 0.5919 - val_categorical_crossentropy: 1.5937\n",
      "Epoch 13/20\n",
      "27719/27719 [==============================] - ETA: 0s - loss: 0.1322 - acc: 0.6558 - categorical_crossentropy: 1.3280\n",
      "Epoch 13: val_acc did not improve from 0.61166\n",
      "27719/27719 [==============================] - 3555s 128ms/step - loss: 0.1322 - acc: 0.6558 - categorical_crossentropy: 1.3280 - val_loss: 0.1467 - val_acc: 0.6064 - val_categorical_crossentropy: 1.4756\n",
      "Epoch 14/20\n",
      "27719/27719 [==============================] - ETA: 0s - loss: 0.1312 - acc: 0.6594 - categorical_crossentropy: 1.3176\n",
      "Epoch 14: val_acc improved from 0.61166 to 0.61580, saving model to C:\\Users\\mdc20\\best_model_14_class_lr@0.0001-1665971573.2646348.hdf5\n",
      "27719/27719 [==============================] - 3556s 128ms/step - loss: 0.1312 - acc: 0.6594 - categorical_crossentropy: 1.3176 - val_loss: 0.1442 - val_acc: 0.6158 - val_categorical_crossentropy: 1.4664\n",
      "Epoch 15/20\n",
      "27719/27719 [==============================] - ETA: 0s - loss: 0.1303 - acc: 0.6623 - categorical_crossentropy: 1.3104\n",
      "Epoch 15: val_acc improved from 0.61580 to 0.61657, saving model to C:\\Users\\mdc20\\best_model_14_class_lr@0.0001-1665971573.2646348.hdf5\n",
      "27719/27719 [==============================] - 3555s 128ms/step - loss: 0.1303 - acc: 0.6623 - categorical_crossentropy: 1.3104 - val_loss: 0.1449 - val_acc: 0.6166 - val_categorical_crossentropy: 1.5071\n",
      "Epoch 16/20\n",
      "27719/27719 [==============================] - ETA: 0s - loss: 0.1295 - acc: 0.6637 - categorical_crossentropy: 1.3030\n",
      "Epoch 16: val_acc did not improve from 0.61657\n",
      "27719/27719 [==============================] - 3556s 128ms/step - loss: 0.1295 - acc: 0.6637 - categorical_crossentropy: 1.3030 - val_loss: 0.1449 - val_acc: 0.6153 - val_categorical_crossentropy: 1.4778\n",
      "Epoch 17/20\n",
      "27719/27719 [==============================] - ETA: 0s - loss: 0.1287 - acc: 0.6683 - categorical_crossentropy: 1.2958\n",
      "Epoch 17: val_acc did not improve from 0.61657\n",
      "27719/27719 [==============================] - 3555s 128ms/step - loss: 0.1287 - acc: 0.6683 - categorical_crossentropy: 1.2958 - val_loss: 0.1546 - val_acc: 0.5986 - val_categorical_crossentropy: 1.6321\n",
      "Epoch 18/20\n",
      "27719/27719 [==============================] - ETA: 0s - loss: 0.1279 - acc: 0.6697 - categorical_crossentropy: 1.2885\n",
      "Epoch 18: val_acc did not improve from 0.61657\n",
      "27719/27719 [==============================] - 3551s 128ms/step - loss: 0.1279 - acc: 0.6697 - categorical_crossentropy: 1.2885 - val_loss: 0.1526 - val_acc: 0.5966 - val_categorical_crossentropy: 1.5716\n",
      "Epoch 19/20\n",
      " 2945/27719 [==>...........................] - ETA: 49:53 - loss: 0.1272 - acc: 0.6728 - categorical_crossentropy: 1.2849"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mUbuntu-20.04\\home\\mdc20\\repos\\personal\\project-fashion-finder\\ModelTraining2.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/ModelTraining2.ipynb#X16sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# from tf.keras.losses import BinaryCrossentropy\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/ModelTraining2.ipynb#X16sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/ModelTraining2.ipynb#X16sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m# cce = tf.keras.losses.CategoricalCrossentropy(reduction=tf.keras.losses.Reduction.SUM, from_logits=False)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/ModelTraining2.ipynb#X16sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m# bce = tf.keras.losses.binary_crossentropy\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/ModelTraining2.ipynb#X16sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/ModelTraining2.ipynb#X16sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m# bce = BinaryCrossentropy()\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/ModelTraining2.ipynb#X16sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     full_model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/ModelTraining2.ipynb#X16sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m                     optimizer\u001b[39m=\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdamax(learning_rate\u001b[39m=\u001b[39mlearning_rate, beta_1 \u001b[39m=\u001b[39m \u001b[39m0.9\u001b[39m, beta_2\u001b[39m=\u001b[39m\u001b[39m0.99\u001b[39m),\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/ModelTraining2.ipynb#X16sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m                     metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39macc\u001b[39m\u001b[39m'\u001b[39m, tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mCategoricalCrossentropy()],\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/ModelTraining2.ipynb#X16sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m                     )\n\u001b[1;32m---> <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/ModelTraining2.ipynb#X16sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     history \u001b[39m=\u001b[39m full_model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/ModelTraining2.ipynb#X16sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     train_dataset, \n\u001b[0;32m     <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/ModelTraining2.ipynb#X16sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     validation_data \u001b[39m=\u001b[39;49m val_dataset,\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/ModelTraining2.ipynb#X16sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     workers\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/ModelTraining2.ipynb#X16sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/ModelTraining2.ipynb#X16sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[checkpoint]\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/ModelTraining2.ipynb#X16sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/ModelTraining2.ipynb#X16sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     histories\u001b[39m.\u001b[39mappend(history)\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/ModelTraining2.ipynb#X16sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(histories))\n",
      "File \u001b[1;32mc:\\Users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "import time\n",
    "histories = list()\n",
    "for learning_rate in [0.0001]:\n",
    "\n",
    "    checkpoint = ModelCheckpoint(\"C:\\\\Users\\mdc20\\\\best_model_14_class_lr@\" + str(learning_rate) + \"-\" + str(time.time()) + \".hdf5\", monitor='val_acc', verbose=1,\n",
    "        save_best_only=True, mode='auto', period=1,)\n",
    "# from tf.keras.losses import BinaryCrossentropy\n",
    "\n",
    "    # cce = tf.keras.losses.CategoricalCrossentropy(reduction=tf.keras.losses.Reduction.SUM, from_logits=False)\n",
    "    # bce = tf.keras.losses.binary_crossentropy\n",
    "\n",
    "    # bce = BinaryCrossentropy()\n",
    "    full_model.compile(loss='binary_crossentropy',\n",
    "                    optimizer=keras.optimizers.Adamax(learning_rate=learning_rate, beta_1 = 0.9, beta_2=0.99),\n",
    "                    metrics=['acc', tf.keras.metrics.CategoricalCrossentropy()],\n",
    "                    )\n",
    "    history = full_model.fit(\n",
    "    train_dataset, \n",
    "    validation_data = val_dataset,\n",
    "    workers=1,\n",
    "    epochs=20,\n",
    "    callbacks=[checkpoint]\n",
    "    )\n",
    "    histories.append(history)\n",
    "\n",
    "print(type(histories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90b98a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdc20\n",
      "Epoch 1/10\n",
      "1991/1991 [==============================] - ETA: 0s - loss: 24.8112 - acc: 0.5546 - categorical_crossentropy: 24.8112\n",
      "Epoch 1: acc improved from -inf to 0.55458, saving model to best_model.hdf5\n",
      "1991/1991 [==============================] - 722s 362ms/step - loss: 24.8112 - acc: 0.5546 - categorical_crossentropy: 24.8112 - val_loss: 18.4811 - val_acc: 0.5966 - val_categorical_crossentropy: 18.4811\n",
      "Epoch 2/10\n",
      "1991/1991 [==============================] - ETA: 0s - loss: 26.5472 - acc: 0.5445 - categorical_crossentropy: 26.5472\n",
      "Epoch 2: acc did not improve from 0.55458\n",
      "1991/1991 [==============================] - 653s 328ms/step - loss: 26.5472 - acc: 0.5445 - categorical_crossentropy: 26.5472 - val_loss: 14.1841 - val_acc: 0.5125 - val_categorical_crossentropy: 14.1841\n",
      "Epoch 3/10\n",
      "1991/1991 [==============================] - ETA: 0s - loss: 34.2294 - acc: 0.5302 - categorical_crossentropy: 34.2294\n",
      "Epoch 3: acc did not improve from 0.55458\n",
      "1991/1991 [==============================] - 685s 344ms/step - loss: 34.2294 - acc: 0.5302 - categorical_crossentropy: 34.2294 - val_loss: 44.7962 - val_acc: 0.5584 - val_categorical_crossentropy: 44.7962\n",
      "Epoch 4/10\n",
      "1991/1991 [==============================] - ETA: 0s - loss: 46.5524 - acc: 0.5088 - categorical_crossentropy: 46.5524\n",
      "Epoch 4: acc did not improve from 0.55458\n",
      "1991/1991 [==============================] - 756s 379ms/step - loss: 46.5524 - acc: 0.5088 - categorical_crossentropy: 46.5524 - val_loss: 48.7954 - val_acc: 0.5348 - val_categorical_crossentropy: 48.7954\n",
      "Epoch 5/10\n",
      "1991/1991 [==============================] - ETA: 0s - loss: 62.9802 - acc: 0.4858 - categorical_crossentropy: 62.9802\n",
      "Epoch 5: acc did not improve from 0.55458\n",
      "1991/1991 [==============================] - 685s 343ms/step - loss: 62.9802 - acc: 0.4858 - categorical_crossentropy: 62.9802 - val_loss: 41.6054 - val_acc: 0.6428 - val_categorical_crossentropy: 41.6054\n",
      "Epoch 6/10\n",
      "1991/1991 [==============================] - ETA: 0s - loss: 80.4817 - acc: 0.4680 - categorical_crossentropy: 80.4817\n",
      "Epoch 6: acc did not improve from 0.55458\n",
      "1991/1991 [==============================] - 654s 329ms/step - loss: 80.4817 - acc: 0.4680 - categorical_crossentropy: 80.4817 - val_loss: 167.9760 - val_acc: 0.0849 - val_categorical_crossentropy: 167.9760\n",
      "Epoch 7/10\n",
      "1991/1991 [==============================] - ETA: 0s - loss: 106.0613 - acc: 0.4430 - categorical_crossentropy: 106.0613\n",
      "Epoch 7: acc did not improve from 0.55458\n",
      "1991/1991 [==============================] - 766s 384ms/step - loss: 106.0613 - acc: 0.4430 - categorical_crossentropy: 106.0613 - val_loss: 190.9534 - val_acc: 0.0868 - val_categorical_crossentropy: 190.9534\n",
      "Epoch 8/10\n",
      "1991/1991 [==============================] - ETA: 0s - loss: 136.6615 - acc: 0.4256 - categorical_crossentropy: 136.6615"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mUbuntu-20.04\\home\\mdc20\\repos\\personal\\project-fashion-finder\\ModelTraining2.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/ModelTraining2.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m os\u001b[39m.\u001b[39mchdir(\u001b[39m'\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mUsers\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mmdc20\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/ModelTraining2.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(os\u001b[39m.\u001b[39mgetcwd())\n\u001b[1;32m----> <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/ModelTraining2.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m history \u001b[39m=\u001b[39m full_model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/ModelTraining2.ipynb#X15sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     train_dataset, \n\u001b[0;32m      <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/ModelTraining2.ipynb#X15sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     validation_data \u001b[39m=\u001b[39;49m val_dataset,\n\u001b[0;32m      <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/ModelTraining2.ipynb#X15sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     workers\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/ModelTraining2.ipynb#X15sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/ModelTraining2.ipynb#X15sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[checkpoint]\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/ModelTraining2.ipynb#X15sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/ModelTraining2.ipynb#X15sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m plot_keras_history(history)\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl.localhost/Ubuntu-20.04/home/mdc20/repos/personal/project-fashion-finder/ModelTraining2.ipynb#X15sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m full_model\u001b[39m.\u001b[39msave(\u001b[39m'\u001b[39m\u001b[39mtype_kernel.keras_model\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages\\keras\\engine\\training.py:1606\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1591\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_eval_data_handler\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1592\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eval_data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39mget_data_handler(\n\u001b[0;32m   1593\u001b[0m         x\u001b[39m=\u001b[39mval_x,\n\u001b[0;32m   1594\u001b[0m         y\u001b[39m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1604\u001b[0m         steps_per_execution\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution,\n\u001b[0;32m   1605\u001b[0m     )\n\u001b[1;32m-> 1606\u001b[0m val_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(\n\u001b[0;32m   1607\u001b[0m     x\u001b[39m=\u001b[39;49mval_x,\n\u001b[0;32m   1608\u001b[0m     y\u001b[39m=\u001b[39;49mval_y,\n\u001b[0;32m   1609\u001b[0m     sample_weight\u001b[39m=\u001b[39;49mval_sample_weight,\n\u001b[0;32m   1610\u001b[0m     batch_size\u001b[39m=\u001b[39;49mvalidation_batch_size \u001b[39mor\u001b[39;49;00m batch_size,\n\u001b[0;32m   1611\u001b[0m     steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[0;32m   1612\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   1613\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   1614\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   1615\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   1616\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1617\u001b[0m     _use_cached_eval_dataset\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1618\u001b[0m )\n\u001b[0;32m   1619\u001b[0m val_logs \u001b[39m=\u001b[39m {\n\u001b[0;32m   1620\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mval_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name: val \u001b[39mfor\u001b[39;00m name, val \u001b[39min\u001b[39;00m val_logs\u001b[39m.\u001b[39mitems()\n\u001b[0;32m   1621\u001b[0m }\n\u001b[0;32m   1622\u001b[0m epoch_logs\u001b[39m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[1;32mc:\\Users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages\\keras\\engine\\training.py:1947\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1943\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1944\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m, step_num\u001b[39m=\u001b[39mstep, _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m   1945\u001b[0m ):\n\u001b[0;32m   1946\u001b[0m     callbacks\u001b[39m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m-> 1947\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtest_function(iterator)\n\u001b[0;32m   1948\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1949\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    952\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    953\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 954\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    955\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    956\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    957\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\mdc20\\anaconda3\\envs\\gpu3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from plot_keras_history import show_history, plot_history\n",
    "import os\n",
    "os.chdir('C:\\\\Users\\\\mdc20\\\\')\n",
    "print(os.getcwd())\n",
    "\n",
    "\n",
    "\n",
    "plot_keras_history(history)\n",
    "\n",
    "full_model.save('type_kernel.keras_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e44556e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history3 = full_model.fit(\n",
    "    train_dataset, \n",
    "    validation_data = val_dataset,\n",
    "    workers=1,\n",
    "    epochs=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b083926c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b172830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_model.save('sparse_categorical_cross_entropy.h5')\n",
    "full_model.save('39_acc.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d390f2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('cat_cross_entropy_16_classes.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b23d6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "x_val, y_val = next(val_dataset)\n",
    "y_prediction = model.predict(x_val)\n",
    "print(y_prediction[2])\n",
    "print(y_val[2])\n",
    "print(np.shape(y_prediction))\n",
    "# preds = np.argmax(y_prediction, axis=1)\n",
    "# print(preds)\n",
    "\n",
    "k = 4\n",
    "axis = 1 # Search for top k values in row\n",
    "top_k_indx = np.argpartition(y_prediction, -4, axis=axis)[-4:].T\n",
    "print(top_k_indx)\n",
    "print(np.shape(top_k_indx))\n",
    "# result = confusion_matrix(y_val, y_prediction, normalize='y_pred=')\n",
    "# print(y_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8302f478",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('gpu3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "b689eaeee660c5f4e77cc22f066091ae7dcd8b72ca1cd0b8aadc4281bbfd7404"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
